TO DO next

1) extend "move array" such that the equality
test is replaced with any function f(X,z) such that when
X is a fresh random number (i.e. z is independent of X), f(X,z) = g(z) up to small proba p.
The equivalence is then:

equiv(move_array(T))
      foreach i<=N do X <-R T; (foreach iX <= NX do OX() := return(X) |
                      	        foreach ieq <= Neq do Oeq(z:T') := return(f(X,z))
<=(#Oeq * p)=> [manual]
      foreach i<=N do (foreach iX <= NX do OX() := find[unique] j<=NX suchthat defined(Y[j]) then return(Y[j]) else Y <-R T; return(Y) |
              	       foreach ieq <= Neq do Oeq(z:T') := find[unique] j<=NX suchthat defined(Y[j]) then return(f(Y[j],z)) else return(g(z))).

z:T' may in fact be several arguments.
The functions f,g can be defined by terms containing several function applications.
We can have several Oeq oracles, each with functions f/g and associated probability p.

This extension could be applied directly to the ROM as well.
(useful for AuthA, OAEP CCA2, ... see below these examples)

As a first step, that could easily be done by allowing the
user to specify the desired function f as an additional
argument to "move array" (actually, the user would write
z:T'; new X:T; f(X,z), generalized to several z and a term 
instead of f), checking that they satisfy the
assumption, which yields the function g and the probability p
by simplifying f(X,z) with X random and z indep of X,
generating the corresponding equivalence as string,
and parsing it.

For ROM, PRF, ..., I could extend cryptogen so that
the user can specify functions used for collisions
with their associated probability.
A possible syntax:
z:T'; new X: T; f(X,z) <=(p)=> g(z)
generalized to several z and terms instead of f/g.
(Putting " new X: T" after "z:T'" suggests that
z' is independent of X.)

The oracle Ocoll could also be generalized:
if new x1:T; new x2: T; forall zi:Ti; f(x1,x2,zi)
simplifies into g(zi) when x1 = x2
h(zi) when x1 and x2 are independent
(zi may depend on x1,x2)
then oracle
Ocoll(a1:input,a2:input,zi:Ti) := f(h(k,a1),h(k,a2),zi)
rewrites into
Ocoll(a1:input,a2:input,zi:Ti) := if a1 = a2 then g(zi) else h(zi)

It can be further generalized to more than 2 random values
by considering the various equality cases between the random
values and testing them on the arguments of the hash function
in Ocoll on the RHS:
new xi:T (i \in {1...n}); forall zk:Tk; f(xi,zk).
Let P = { (i,j) \in {1...n}^2 | i<j }.
For each S subset of P,
f(xi,zk) simplifies into g_S(zk)
when xi are random,
for (i,j) \in S, xi = xj,
for (i,j) \in P\S, xi is independent of xj,
and zk may depend on xi.
Then the oracle 
Ocoll(ai:input,zk:Tk) := f(h(k,ai),zi)
rewrites into
Ocoll(ai:input,zk:Tk) := let S = {(i,j) \in P | ai=aj} in g_S(zk)
that is, we test the equalities among the ai's to select
the right simplified expression g_S(zk).

vars:types; new X:T; M1 <=(p)=> M2
check
- all elements of vars are pairwise distinct,
   different from X, different from predefined identifiers (true, false, not, bottom, bitstring, bitstringbot, bool). They are distinct from types in [types].
   Types in [types] are different from predefined functions = true, false, not, bottom.
   Identifiers in M1,M2,p  are distinct from types in [types] and predefined types (bitstring, bitstringbot, bool). Those in vars are considered as variables, the others as constants (fcts of arity 0).
   Function symbols in M1,M2,p are distinct from vars and from types in [types] and predefined types (bitstring, bitstringbot, bool).
   Functions are always used with the same arity. (Types are too hard to check.)
- M1,M2 contain only PIdent, PFunApp, PEqual, PDiff, POr, PAnd
- all vars and X occur in M1, and there are no other variables in M1
- all variables of M2 are in vars.
- T is the output type of the hash function.
- all variables in p are in vars.
Rename all variables in vars and X to v_<oldname>
all non-predefined functions in M1, M2, p to fun_<oldname>
(predefined functions = true, false, not, bottom)
all non-predefined types in types to t_<oldname>
(predefined types = bitstring, bitstringbot, bool)
Add all the renamed types and function symbols to the arguments of the macro.

Or would it better to generate the required macros on the fly, inside CryptoVerif itself?
Some names of macros would then be internal, and not redefinable by the user.
Advantages:
- we can generate exactly what we need: any number of arguments, any number of oracles,
collisions specified by the user at "equiv" time... -> no, the collisions should rather
be specified at expand time, because we may want to apply the equivalence with collisions
automatically. That could be done by allowing expand to take other arguments
than identifiers for internal macros:
  - int, e.g. for the number of arguments of hash functions, PRFs.
  In fact, the best way to specify the number of arguments would be to allow tuples
  of identifiers as argument of expand. We would then pass the tuple of input types
  as argument of expand.
  - string, e.g. for collisions used in hash functions, PRFs, ...
Only the *_partial equivalences are better generated at equiv time since they
can be applied only manually, and that allows to generate the appropriate number
of OH/Oeq oracles by looking at the oracles mentioned in the [terms:...] argument of equiv.
Drawbacks:
- we still need to generate a library for ProVerif; it will be more limited than the
CryptoVerif internal macros
- it is much harder for the user to modify the macros, as we did e.g. for Wireguard.
(ROM_hash_refactored)


Specify IND$-CPA

Document rom_partial / prf_partial
Apply it to PRP, SPRP, ICM, PRF_ODH (variable number of arguments,
variable position of the DH argument, equiv prf_odh_partial(prf)
with variable number of prf oracles)

Document the "cryptogen" program

Look at Tamarin paper to improve proverif DH model
for curve25519/448/single_coord_ladder
DH_good_group(high_t, Z, g_high, exp_high, exp_high', mult):
  fun exp_high(high_t,Z):high_t.
  const g_high.
  equation exp_high(exp_high(g_high,x),y) = exp_high(exp_high(g_high,y),x).
const id_low: low_t.
const id_high: high_t.
fun elem(low_t,high_t):G.
g = elem(id_low,g_high).
zero = elem(id_low,id_high).
reduc changelow(elem(x,y),x') = elem(x',y).
reduc exp(elem(x,id_high),n) = elem(id_low,id_high)
otherwise exp(elem(x,y),n) = elem(id_low,exp_high(y,n))

2) allow "query equiv ..." to prove an equivalence
   presented exactly as CryptoVerif accepts assumptions on
   cryptographic primitives.
   Warning: be careful with [computational] equivalences:
   proving them requires triggering an "event bad" when the
   result of the two sides differs, and showing that event bad has
   a negligible probability of happening.
   [unchanged] restrictions are shared between both sides.

3) Extend depanal2 and simplify so that they apply to
   non-expanded games (see point 6 in HIGH PRIORITY)
4) Implement the "choice" construct in CryptoVerif
   (see point 2 in HIGH PRIORITY)
5) Guess the tested session (see point 4 in HIGH PRIORITY)

HIGH PRIORITY

0) Track all remaining [occ not set] to avoid them.
- "Transformed test at ... into a logical formula"
   case STestEElim in transf_simplify.ml
   creates new terms with occurrence not set, which are then simplified.
   I have improved a bit by preserving the occurrence when the result of
   STestEElim is a simple term.
   Possible fixes:
   - do the transformation into logical formula in the expand transfo
     instead of simplify
     pb: TestE may appear as a result of simplifying a FindE,
     and in this case, STestEElim would not be done by expand,
     until we redo a full expand, usually after a crypto transformation.
   - have a notion of approximate occurrence; we would use the
     occurrence of TestE as approximate occurrence for the new terms.
     It would be displayed "at about ..."
   - instead of expanding and further simplifying in the same pass,
     force a full expansion pass after simplification in case STestEElim
     does not yield a simple term.
     Pb: much useless work since only a tiny part of the game
     really needs to be expanded...
- When I transform let in transf_simplify:
      let plet = Terms.put_lets bind ptrue pfalse in
      let ptest = Terms.oproc_from_desc_at let_p (Test(test, plet, pfalse)) in
      simplify_oprocess cur_array dep_info true_facts ptest
The "let"s created by Terms.put_lets do not have a proper occurrence.

   1) We cannot apply crypto transformations to equalities outside
   the game itself, e.g. equalities obtained during proofs of
   correspondences. In contrast, we can apply collision statements
   to these equalities.

   E.g. suppose H is *hidden-key* collision resistant
   K = H(hk, (..., A,B))
   We want to prove absence of UKS attacks, ie.
   event(Aaccepts(K,A1,B1)) &&
   event(Baccepts(K,A2,B2)) ==> A1=A2 && B1=B2.
   We get
   H(hk, (...,A1,B1)) = H(hk, (...,A2,B2))
   since the key K is the same on both sides.
   We should conclude A1=A2 && B1=B2 by
   collision resistance of H, but cannot do that
   because we cannot apply the crypto transformation
   that defines hidden-key collision resistance
   (which is particular needs to check that all
   usages of hk are in H(hk, ...)).
   It works with (public key) collision resistance
   because it is a collision statement, which
   does not need to check anything about hk.

   To solve this issue, we should allow applying crypto
   transformations to expressions when the whole game is
   is an instance of the LHS of the crypto transformation
   with oracles that are left unchanged in the RHS.
   Then only the target expression is modified.

   Obviously, another way to solve this issue without modifying
   CryptoVerif at all is to encode the correspondence
   using tables (insert at event Aaccepts and Baccepts,
   and have a process that executes event session(A1,B1,A2,B2) when it
   read Aaccepts(K,A1,B1) and Baccepts(K,A2,B2) from the tables.
   Then the equality test H(hk, (...,A1,B1)) = H(hk, (...,A2,B2))
   is in the game itself.

   The same issue also appears in the reductions done
   for find_compos: showing the injectivity of
   H(hk, ...) requires checking that hk is used only in
   H(hk, ...). The trick above with tables does not work
   in this case.
   
2) Incompatible front-end, second step

   - if ... then .. !i<=N ..let x =
            else .. !i<=N ..let x =
   is probably rejected, although it can be generated by CryptoVerif,
   because CryptoVerif gives different names to the 2 replication indices
   i, so the two occurrences of x do not have the same args_at_creation.
   Reuse replication indices? when they have the same name (identifier),
   the same replication indices above them, and are in different branches
   of if/let/find/get? I need to choose replication indices in the pass
   check_process1.

   - In practice, when I really want to read intermediate games,
   CryptoVerif should create a specific environment from the initial
   game, containing all functions (even those local to macros) as well
   as constants cst_<type> and events introduced by CryptoVerif.
   
   - in ProVerif, allow replication indices in events, tables, and
   arguments of processes and letfun (replication indices correspond
   to the session identifiers of ProVerif)

   - Encode more ProVerif queries in CryptoVerif
choice[M1,M2] in ProVerif can be coded in CryptoVerif by 
choosing new b:bool at the beginning and 
replacing choice[M1,M2] with "if b then M1 else M2"
      We prove the secrecy of b.

      Right-now, a common encoding can be obtained using a macro:

      let b = choose_bit() in
   -> letfun choose_bit() = choice[true,false] in ProVerif
   -> query secret b.
      letfun choose_bit() = new b: bool in CryptoVerif
      
      test(b, M1, M2) defined as a destructor in ProVerif.
      either as function with a few properties (test(b,x,x) = x,
      f(test(b,M1,M2)) = test(b,f(M1),f(M2)),...)
      or as if b then M1 else M2 in CryptoVerif (leads to expansion).

      But needs a test function for each type, while choice is
      polymorphic in ProVerif. Better results would be obtained
      by using choice as input, encoded in CryptoVerif by a special
      test function with homomorphic properties and that can be
      expanded to "if b then M1 else M2" when desired.
      For the expansion of "test(b,M1,M2)" into
      "if b then M1 else M2", use the "replace" command.
      Extend it to accept "if" in the new term,
      transform "if" into "test" before checking equality
      with the old term.
      When the new term contains "if", the resulting
      is not expanded.
      Call "expand" after "replace" to expand it when
      auto_expand is set.
      

noninterf x in ProVerif can be coded in CryptoVerif by 
receiving m1,m2 at the beginning 
choosing new b:bool
defining x = if b then m1 else m2
We prove the secrecy of b.

We could probably push this idea for noninterf x among S.

   Also have the query "equivalence P1 P2" (transform P1 and P2
   into the same game).
   -> DONE 24/08/2018 
      TO DO in ProVerif, allow "equivalence P1 P2 public_vars x1,...,xn".
      
   When I show that G1 is indistinguishable from G2, I transform
   G1 and G2 into a common game G3. Now, this common game cannot
   contain events introduced by Shoup Lemma during the proof,
   because insert_event always introduces a fresh event, so
   the same event cannot be introduced from both sides of the proof.
   Would it be good to change that?
   If I change it, it is enough to count the probability of these
   common Shoup events in G3 once (see cryptoverif.tex, sect 2.7.4),
   so I would get a better probability than by eliminating these
   events on both sides of the proof.
   I should be careful that the introduced Shoup events do not
   occur in G1 and G2. However, I could reuse the same
   events several times.
      
   Also query secret x [reachability] (the adversary cannot compute x).

3) 
PRF-ODH: I think "success simplify" and "focus" 
would help for working with PRF-ODH
=> Benjamin Lipp will look at that
      
4) Guess the tested session; event adversary loses/adversary wins; ...
   
- Support authentication via
    A -> B: {N_A, A}_{pkB}
    B -> A: N_A
This is related to global dependency analysis.
After applying the security of encryption, A makes a test
N_A'(received) = N_A(generated by A),
while B outputs N_A. Nothing else depends on N_A.
If B did not run, the global dependency analysis
would show that the test N_A' = N_A fails, therefore
A is assured that B did run.
That might be implemented by allowing the dependency analysis
to return facts that it inferred, in addition to the
simplified form of a term.
==> Probably useful for TLS, to prove forward secrecy for the
PSKDHE mode.
More generally, it is sometimes useful to apply crypto transformations
to "partial" games, e.g., to prove the suf_cma_corrupt equivalence
from the suf_cma one (same for signatures), or in the proof of OTR.
It could be done as follows:
we want to show that some program point P2 is unreachable
unless some other program point P1 has been reached.
We can represent P1 as the definition of a variable x,
and we insert a test and an event at P2, so that it becomes:
   if defined(x) then P2 else event advwins.
If the only property we want to prove is that "advwins"
is unreachable, then we can insert an event "advloses"
just after the definitions of x, and thus remove the
part of the game that follows the definition of x.

More generally, if the only property we want to prove is that "advwins"
is unreachable and we can prove that x is not defined when "advwins" is
reached, then we can insert an event "advloses" just after the 
definitions of x. (This is done by "success simplify".)

- TLS: github/ProtoTLS/cv/tls13-core.cv
* It does not work with DDH. To make it work, 
I would need to guess the tested session, and apply DDH only
in that session. Some difficulties:
   - I don't know how to express in CV that the tests in the
   tested session all succeed until the desired secret key is defined.
   (I need to express that it is known from the start that all these
   tests *will* succeed.)
   - What happens for the independence property between the session
   keys? I cannot prove it if I have a single session. It is enough
   to reveal keys of other sessions to the adversary. If the key
   of the tested session is still secret, it proves independence.

   When I guess the tested session, replace:
   ! i <= N Q with ! i <= N Qtest
   where Qtest is obtained by replacing the process P
   under the first input with if i = i_tested then P else P'.
   SArenaming will rename variables of P to two different names
   if needed.
   i_tested is a constant.
   P' is obtained from P by
      - removing end events of correspondences
      - removing (or renaming if they are used otherwise) definitions
        of variables with query "secret1".
      - replacing (and renaming if they are used otherwise) definitions
        of variables with query "secret" with an output of their value
        to the adversary.
   The probability of attack must be multiplied by N.
   (If there are several replications, guess values for all of them?
   Still only those above the "required step" [defined below].
   Or allow the user to choose which replications will be guessed?)

   => Sometimes, I derive a contradiction but I need to leave some
   code. Would it be better to use AdvLoses instead of Yield?

   I am wondering if the changes to guess the tested session,
   event adv loses, etc would allow CV to prove the next two examples:
   
- examples/basic/needham-schroeder-skcorr.pcv
  Example to improve in CV (show that A must have decrypted for B to
  get his message)
  That should allow to prove (inj-)event(fullB(A, k, x)) ==>
  (inj-)event(fullA(B, k, x))
  Similar remark for file examples/basic/needham-schroeder-sk.pcv and
  query event(fullB(A, k, x)) ==> event(fullA(B, k, x))

- examples/basic/needham-schroeder-pkcorrKeyN{a,b}.pcv
  CV does not manage due to ordering pb (or to key Na/Nb leaked too early?)

* It does not work automatically with the logs as they presented.
Investigate in more details why (perhaps a bad orientation of
equalities?), and fix it.

6) Sometimes, the size of the game tends to explode. To avoid that, we
could use constructs that allow comon continuations for several
branches:

begin
   find ....

end;
P

This is equivalent to plugging P instead of yield at the end of 
all branches of the inner process.
Same thing for "if" and "let pat = M in P else P'"
(The case "let x = M in P" in fact has a single continuation.)
Do we want to add the continuation to the contructs "find", "if",
"let", or to have a generic construct "begin P end; P'"?
The latter may be better.

In fact, I think the generic construct should be a "merge"
instruction, similar to a phi-function in SSA.
* Can be displayed by showing "l: P" in one branch
and "continue l" or "goto l" in the other branches that
have the same continuation.
* New transformations:
   - Push the merge forward, distinguishing cases further,
   or even remove it completely.
* Effect on the game transformations:
   - Collection of true facts: store the true in the merge
      instruction for each branch. At the last branch,
      compute the intersection of true facts and analyze the
      continuation with that information.
   - Simplify: as above.
   - Expand: have a mode in which merge instructions are
      used to avoid duplicating code in expansion.
   - Crypto: almost no change, I think; the change is in expand.
   - RemoveAssign: if the variable x on which we remove assignments
      is used in the continuation (without array access), then
      it must have the same definition in all branches that
      have the same continuation.
      Otherwise, I need to push the merge after the usage of x first.
   - SA rename: when the SArenamed variable x is defined
      in several merged branches, it must not be used in the
      continuation after the merge.
      Otherwise, I need to push the merge after the usage of x first.

* Other ideas to solve the same problem:
   - Allow more game transformations on unexpanded games
      (e.g. remove_assign, SArename, crypto). That would allow
      applying possibly several rom + GDH without expanding the game, and then
      expand the game afterwards, when some cases have been removed
      thanks to GDH.
      That might be easier to implement and perhaps also to use
      (no need to move merge points manually, for instance),
      but less powerful.

      It should work well when we have a single ROM followed by
      GDH or CDH, or several ROM each after a possibly common Diffie-Hellman.
      But it probably does not work that well in case we have several ROMs
      in sequence (e.g. it would not work well for TextSecure, or for Wireguard
      without applying our indifferentiability result): the first ROM leads to

      let result = find... then r[...] else new r: T; r in
      H2(result, ...)

      The second one yields

      let result = find... then r[...] else new r: T; r in
      find ... result = result[...] && ... then r2[...] else new r2:T2; r2

      To simplify result = result[...], I need to distinguish cases at
      least locally.

      Perhaps it works better in the other order:

      let result = H1(...) in
      find ... result = result[...] && ... then r2[...] else new r2:T2; r2

      remove_assign result

      find ... H1(...) = H1(...) && ... then r2[...] else new r2:T2; r2

      No, I think that's not good at all: that will yield many more occurrences
      of H1 (each call to H1 is copied at each call to H2),
      plus H1 now occurs in conditions of find so the transformations that
      we can make are more limited.
      => Now much better with the improved ROM model that
      simplifies H1(X) = H1(Y) into X = Y.

      Transformations that already support unexpanded games:
      - remove_assign
      - sarename (flag expanded to set accordingly)
      - crypto
      - auto_sa_rename
      - transf_tables [applied on the initial, unexpanded game]
      - insert_event [here, the difference is that we can insert the
        event in a term]
      - replace
      - success (except equivalence queries)
      - check_distinct 
      - check_corresp

      Transformations and other code that do not support them:
      - Simplify1.improved_def_process
      - globaldepanal
      - simplify (including depanal2) When simplify works on
        unexpanded games, I could use it as the pre-expansion
        simplification pass instead of using a specific transformation. 

Regarding depanal2:

The dependency information computed by DepAnal2 at the definition
of a variable x and saying that a certain term M does not depend on a certain
variable y could also be used when x[M1...Ml] is known to be defined
(after substituting M1...Ml for the current replication indices in M and y).

Complete the list of independent terms in dependency analyses using
simp_facts: 
* Add to the list of values known to be independent,
values that are equal to values already known to be independent.
(Equality comes from simp_facts)
* If f(M1...Mn) is independent and f is [data], then M1,...,Mn are independent.
* If M is independent and is of the form C[x1...xn] where C consists of applications
of function symbols and x1...xn are variables (possibly with indices).
Let y1...yn, z1...zn be fresh variables (without indices).
Simplify the equality C[y1...yn] = C[z1...zn].
If the obtained result is C'[y_{i1}...y_{in'}] = C'[z_{i1}...z_{in'}],
then C'[x1...xn] is independent.
   (See ~/repos/verified-noise/WG.25519.AB.dyn.replay_prot.failure
   Solved another way for the Wireguard case study.)
[That point may be hard and costly, I could also abandon that.]

      - insert
      - merge
      - move
      - expand [should allow partial expansion guided by the user]
      - success [equivalence queries]

   - Have an indifferentiability toolbox:
      - Oracles with disjoint domains => independent oracles
      - Concatenation of independent oracles => single oracle
      - Truncation of random oracle
      - Chaining:
         a) H2(H1(x),y) => H(x,y)
	 b) y = H1(x); concat(y, H2(x,y)) => H(x) (HKDF)
	 c) Wireguard chaining (cf B Lipp's master thesis)
      
      Implement that in CV?
      Combined with the previous idea, that should solve most cases!
      In particular, it solves the case of ROMs in sequence that was
      problematic for the previous idea.

7) More generally, allow some reordering of instructions:
- move "let"s up, when that reduces the number of occurrences of
  crypto primitives to compute. Risk: we may compute the expression
  more often if we cross tests.
  We could do more with array references: when an expression depends
  on x1[j],...,xn[j] and x1...xn are defined in the same block of code,
  we could precompute the expression after defining x1...xn.
  Risky, except if the expression is always computed, for example if
  it is already computed just after the definition of x1...xn.
- move "new"s (and, if necessary for that, "let"s) down, when that
  allows distinguishing cases (i.e. when we cross a if/find)
  Risk when I move "let"s: duplicating computations, which make the
  size of the game explode.
- move "let"s down when the computed value is used only in a single
  branch of a if/find (or in not all branches of if/find)
Terms in "let"s can be split to do that.

Rather: More fine-grained user guidance:
- Reorder instructions (moving "new" up can be useful, see fdh below;
also for merging of branches until we do some auto reordering),
- decide to expand "if x then m1 else m2" or to keep it as "test(x,m1,m2)",
- perhaps decide to merge or not each if/let/find when the branches execute
the same code, ...

8) common subexpression elimination
examples-1.28/nd/notest/JoeKaiTsayBasicKerberos_071122_INT-CTXT:
Kerberos: to handle "keyderivation" for all keys, use some common
subexpression elimination to avoid recomputing several times the same
key. (This transfo is the contrary to "move_new". Choose when to apply
each transformation. Perhaps use common subexpression elimination when
the considered expression does not depend on the replication index.)
==> Simpler and better: rely on user guidance. Have an instruction
that allows replacing all terms equal to the definition of x
with x. (Apply it also with indices.)

9) improved merging of find branches
auto-reorder the instructions in the branches to merge,
so that they are in the same order.

Instead of fully reordering, rather:
- for variables defined by "let x = M" without array
accesses, replace x with its value.
- for variables defined by "new x" without array
accesses, replace x with a special value "random_i"
- for variables with array accesses, we know that
their name must be preserved [not if the array accesses
are local to one branch! perhaps treat it as "without"
array access in this case?], so it is easier
to match the definitions on both sides. We can reorder
by delaying the definition of the variable in question
as long as we can.
- we will not reorder conditions (if, find, let with
non-variable patterns), events, input, output, ...

The above change would in particular allow to merge

find ... then
   XX
else
   x <- cst_T;
   XX

where x is used only in array accesses of conditions
of find that get removed during the merge
(see e.g. examples/obasic/OAEP.ocv).
Currently, I need to manually add "x' <- cst_T" for some
fresh x' to the first branch before merging.

Another merge improvement useful for examples/obasic/OAEP.ocv:

find ...C1... then
    XX
else
  find ...C2... then
     XX
  else
     XX

gets merged in two steps. First

find ...C1... then
    XX
else
    XX

then XX. It could in fact be merged in one step.
This is important because

find ...C1 (uses x)... then
    XX
else
  find ...C2... then
     XX
  else
     x <- cst_T;
     XX

does not get merged: the usage of x in C1 prevents the first
merge step above. It could be merged if CryptoVerif was able to
do it in one step. (Currently, I need to manually rewrite into

find ...C1 (uses x)... then
    XX
orfind ...C2... then
    XX
else
    x <- cst_T;
    XX

by inserting
  find ...C1 (uses x)... then
  orfind ...C2... then
and simplifying, then add x' <- cst_T to the first two branches,
then merge.)

10) Add more comments, e.g. in terms.mli

11) Make an up-to-date tech report describing CryptoVerif.
With respect to EPrint 2005/401, the following changes are needed:

    * Move to exact security (use the definitions of CSF'12;
see also the Marktoberdorf chapter)

    * Include correspondences (see CSF'07)

    * Extend the game language: add the abort construct,
add if/let/find/new in terms (including find conditions),
add find[unique]

    * Distinguish the language for the initial games (with insert/get
in tables) and the language for internal games (with find).
Show that the translation is correct.

    * section D.2.4 Relaxing H'2:
        ** There was a bug in cryptotransf.ml in the computation of
probabilities when transformed terms occur in "find" conditions (these
terms are executed as many times as the condition is evaluated, that is,
the number of executions of "find" times the number of values of indices!).
[FIXED, DONE improved the precision by removing the useless indices.
Mentioning this point in the report makes sense only with exact security]

        ** The extension of section D.2.4 has been further extended
by supporting if/let/find/new in conditions of "find". The conditions
on occurrences of expression that came from expansion are removed, but:
          *** There was an even more serious bug when the crypto
transformation transforms a term in a find condition
    find j<=N suchthat ... m[j]...
by introducing a find on m.
Property enforced by check.ml: the "find" is never done on the input 
variable directly. If we want to do a find on a input, we put this
input in a variable defined by "let" and do the find on that variable.
Consequence: if M' is the transformed expression in the RHS, we just need
to check that the RHS makes no find on a variable defined in M'. [FIXED]
          *** Variables in a condition of find must have a single definition.
=> do not share "let"s for such variables in cryptotransf.ml [FIXED]
          *** For simplicity, now, I transform a condition of find
only when it is a term without if/let/find/new, and in this simple
case one can proceed without the "real" list of indices, which
includes indices of replications but also the indices of find.  To go
further, we could associate to each variable defined in the condition
of "find" its "real" list of indices.

    * I should add a section "Relaxing H1", that deals with the use of
variables with array accesses in the LHS (CryptoVerif 1.10).

    * Also add events in the RHS of equivalences (for DDH)

    * Update the proof strategy

    * Add the merging of if/find branches in simplification

    * Add merge_branches, merge_array, move array

    * Add find[unique]; update random oracle model and ideal cipher
model with find[unique] and Oeq.

    * Fix problem in the semantics [FIXED in the implementation,
      update tech report]
there is something strange in the semantics:
in "find u <= N suchthat defined(...) & M then ..."
u[curr. repl. index] is considered defined in M (to the value currently under inspection), 
which may cause unexpected behaviors if we use u[M'] for some other M'.
Fix: consider
find u[\tilde i] = i' <= N suchthat defined(def_list) & M then P ...
u is a variable (array), i' is a replication index.
i' is used inside def_list and M, to perform the array lookup, 
u[\tilde i] is then set of a successful value, and used inside P.

The old semantics was strange in several respects:

   * Computation of probabilities: one needed to add find indices to
   the replication indices. Now, all indices are considered together.

   * Definition of variables: when a find index was known to be
   defined, one was not sure that the condition of find was true,
   because one may also be inside the condition of find itself.
   Now, when the variable find index is defined, the condition of
   find is true.

   * Args_at_creation for variables defined in conditions of find:
   Args_at_creation of these variables was cur_array, containing only
   the replication indices above the find, which was not
   logical. Indeed, these variables take a different value for
   each replication index but also for each find index.
   This was not too problematic because we forbid array accesses
   to these variables. Now, args_at_creation contains all replication
   and find indices.

   * When the condition of find made an array access to an index
   of that find, the semantics was counter intuitive: the index was
   considered already defined at the currently tested value.

There are still some drawbacks with the new semantics:

   * We very often need to substitute a replication index with
   a variable and conversely. For instance, in 
   find u = i <= n suchthat defined(def_list) && t then P else Q,
   the facts that hold in P are t{u/i}, not t itself.

   * When the indices of find change, we need to rewrite the condition
   of find to update the value of cur_array/args_at_creation.
   For instance, when we manage to know the value of a find index,
   and so substitute it with its value, the index must be removed from
   cur_array.

   * When we expand find in condition of find, if the inner find
   makes an array access to the indices of the outer find, we
   need to duplicate the branch, distinguishing whether that array
   access is done with the current indices or with other indices.

I still think that the new semantics is much cleaner.

   * Document [unchanged], [computational]

12) Make a tutorial

MIDDLE PRIORITY

13) Strengthen the global dependency analysis like the proof of one-session
secrecy; one could even use a single dependency analysis for both.
(For instance, with the current code, in the case of forward secrecy,
CryptoVerif may be able to prove secrecy of x, but not to prove that
x cannot be computed by the adversary, because it would need to show
x = x' is impossible by global dependency analysis, but that analysis
does not use elsefind facts, does not use compability of program points, ...)
Group all dependency analyses into one stronger one?
(That does not seem obvious to do.)

14) We could add a transformation that removes part of the code,
by giving to the adversary all data that it needs in order
to run that part of code by itself.
It should adjust the probability computation by adding the runtime
of the removed part to the runtime of the adversary.
That allows to simplify the code.
   
15) Since the speed of Terms.equal_terms is so important, it
is likely that a better structure for sets of terms,
which would reduce the number of equality tests, would yield 
a huge speedup.
In fact, perhaps not that much: Terms.equal_terms seems to take
6-10% of the time (when considering only commutative fct symbols), 
so optimizing equality tests would save at most that time.
However, Facts.simplif_add[_list] seems to take most of time (60%),
optimizing it might yield good speedups.
Facts.apply_eq_statements_and_collisions_subterms_once seems to be the costly part.

I could optimize Facts.try_no_var by storing its result in the term,
together with the substitution list (to reuse it only when the
substitution list is unchanged). To be efficient, I would need to
avoid making useless copies of terms, so that terms are as often
as possible physically equal.

16) Interface improvements:
- Perhaps omit the display of games between remove_assign useless, 
simplify, move_new_let.
- the lines are sometimes much too long in Latex output
- detailed description of the transformations:
  * when simplification modifies several times the same term/process,
  the occurrence after the first modification is no longer found in the
  initial game
  * when a simplification step duplicates code, the occurrence
  becomes ambiguous.
  * when I simplify a term during expansion, the occurrence is not
  found in the initial game.
- HTML interface?
- during manual proofs, have the tool suggest possible game
transformations (via a command "suggestions", or in background
while it is waiting for the user to type his command)

17) Files that could benefit from improvements:

examples/fdh,pfdh: we cannot allow the hash oracle do be called
before generating r, because we need r to be defined in the hash
oracle, after some game transformations.
We should start from a game like
       in(hstart, ()); new hk: hashkey; out(hret, ());
       ((!hashoracle) | (kgen ; (!sign | !verify)))
A key r chosen in kgen is needed in hashoracle after a game
transformation. In this case, we should move the generation of r
upwards; it would end up being generated in the same block as hk,
and we could then apply the game transformation as desired.

examples-1.28/nd/notest/needham-schroeder-pkcorr3Block-improve-secrecyNa.cv:
One could prove the secrecy of NaA/NaB by improving the 
dependency analysis: there are equality tests between Na_270 and
values that do not depend on it (see that file for details).

examples-1.28-converted/nd/test/Misha-injectivity_and_equality.cv:
there is an equality x = g(x') that cannot be oriented because
x is defined by "new", and it should be oriented.
4/09/2013: now works manually; it would still be nice
to make it work automatically.

EKE:
- In Simplify1.is_compatible_indices, exploit defined variables using 
CompatibleDefs2.check_compatible2_deflist to show that indices are
incompatible.
- In Simplify1.same_oracle_call, use a form of antiunification, 
to show that more calls are in fact calls to the same oracle.
- new proof of EKE in oexamples/OEKE.ocv. In the probability, there is now a term
  (2 qH0 + 3 qH1) pCDH(...). Try to reduce it to (qH0 + qH1) pCDH(...)

- "Expanding and simplifying" is very slow in
~/dev/projects/2014ANRAirbus/ICAO9880-May2017/computational/ATN_functions.cv

- Try to understand why CV explodes on 
2013Airbus/computatinonal_revised/arinc823-secret-key.KEY_SECRECY.ORIGINAL.cv
when I add the commented out code in check_distinct.ml,
   to use elsefind facts.

18) Support for loops and mutable state.
This allows support for stateful crypto primitives.
Also useful in many other situations.

A solution would be to have:

neworacle O; (
let r = O[1](s_1^0, ..., s_n^0) in P else Q
|
foreach i <= n do O[i](s_1: T_1, ..., s_n: T_n) := 
    ....
    if [cond] then 
      return r  (*stop iterating*)
    else
      let r = O[i+1](s'_1, ..., s'_n) in return r else end
)

or using the "loop" construct:

neworacle O; (
let r = loop O((s_1^0, ..., s_n^0)) in P else Q
|
foreach i <= n do O[i]((s_1: T_1, ..., s_n: T_n)) := 
   ....
   return ((s'_1, ..., s'_n), not [cond])
)

The variables s_1, ..., s_n contain the internal mutable state.
The initial state is s_1^0, ..., s_n^0; the state at the next 
iteration is s'_1, ..., s'_n. The loop iterates until the condition
[cond] holds. The final result is the returned value r in the first
case, the final state (s'_1, ..., s'_n) in the second case.
(We can easily add an element in the state to store the final result
if it is not already included in the state.)

Have another construct to encode this structure ? (To make sure that
the oracle calls/the loop are always used in the way above.)
Allow mutable variables, and transform them into this kind of
iterating structure ?

The advantage of the solution proposed above is that it requires
only minimal changes to CryptoVerif. The variables still have a fixed
content for each index. In a first step, it is easy to add the loop 
construct, and leave it unchanged by all game transformations.
In a second step, one needs to add reasoning capabilities taking
into account that s_j[i] is s'_j[i-1], and that the instances of
oracle O are executed in increasing order of the index i, so that
variables with smaller i are defined (if they are defined
in all executions of O), and variables with greater i are not 
defined yet. Some inductive reasoning will probably be needed.
We will need functions +1 and -1 on indices. This will break the
invariant that indices contain only Var elements, which is true
in the current version of CryptoVerif -> need to check that the
current code is still correct in the more general case.

19) Oracle calculus:
Instead of the current calculus, use a higher order calculus,
similar to the *simply typed* lambda calculus, with functions,
tuples and bitstring types.
Primitives are first-order constant functions, axomatized.
The adversary is a variable function, received as input
by the protocol (or the adversary is not written and takes
the protocol as argument).
Some functions can be called only once (write it in their
type?).
This calculus can then be expanded into the current input/output calculus.
Each channel corresponds to an occurrence in the type of the adversary.
Whether we make an input or an output depends on the polarity
of the type.
- applying a known function is beta reduced
- applying a primitive is left as it is
- applying a variable function (adversary) is encoded by
  * outputting the bitstring arguments
  * defining in parallel after the output
    the known functions passed as arguments, under replication
    when they can be called several times
  * ignoring the variable functions passed as argument
  * inputting the result of the function
- receiving a variable function as argument is replaced
  with inputting nothing.
The fact that this expansion works may be related to strong
normalization of the simply types lambda calculus.

Write
"match M with 
 | f(p1...pn) -> ..."
instead of
"let f(p1...pn) = M in ... "?

When we generate an implementation, we make the reverse translation:
we translate the input/output calculus into OCaml, functional calculus.

LOW PRIORITY:

20) Small details

- Infer (1)
collision x <-R Z; y <-R Z; forall X: subG; 
  return(exp_div_k(g_k,mult(x,y)) = X) <=(2*Pcoll1rand(Z))=> return(false) if X independent-of x || X independent-of y. 
from (2)
collision x <-R Z; forall y: Z, X: subG; 
  return(exp_div_k(g_k,mult(x,y)) = X) <=(2*Pcoll1rand(Z))=> return(false) if y independent-of x && X independent-of x. 
The idea would be to apply several times collisions to collect
side conditions, and then try to reduce the term using all side conditions.
E.g. x <-R Z; y <-R Z; 
exp_div_k(g_k,mult(x[i],y[j])) = X
becomes
i = (index of x in X) && exp_div_k(g_k,mult(x[i],y[j])) = X
by applying the collision (2) with x,y,X
then
i = (index of x in X) && j = (index of y in X) && exp_div_k(g_k,mult(x[i],y[j])) = X
by applying the collision (2) with y,x,X for x,y,X.
Then we must reduce the equality exp_div_k(g_k,mult(x[i],y[j])) = X
knowing the values of i and j. Such a reduction may succeed
while no reduction is possible if one knows only i or only j.

However, if we add the probabilities of the collisions that we apply,
we are going to obtain 4*Pcoll1rand(Z) instead of 2*Pcoll1rand(Z).
Is (1) correct with 2*Pcoll1rand(Z)?
I think it's ok because the choice of whether X independent-of x or
X independent-of y cannot itself depend on x or y.
But that's tricky, and difficult to generalize using the idea above.

- Links created by Facts.replace_term_repl_index are probably
never removed. Is that a problem? Perhaps not.

- Set future binders/true facts in terms in Terms.build_def_process

- (OPTIONAL) In Terms.build_def_process, collect facts known to be true at the
   end of a term. After "Event_abort" the execution does not continue,
   so everything is true. Hence for instance, after
   "if t1 then t2 else event_abort e", t1 is true and the facts
   guaranteed by t2 are true.
   WARNING: This does not allow saying that t1 and the facts
   guaranteed by t2 are true in the future_facts!
   That would not be correct in the proof of correspondences:
   the correspondence needs to be proved even if the game terminates
   with abort.
   
- Better exploit compatibility tests:
* improve case distinctions in Facts.add_facts, version for
  the proof of correspondences: when I assume that a variable
  is defined at a certain point, this implies that other variables
  are also defined at certain points and not others.
  This requires testing compatibility between program points.

- Keep more information about the crypto transformation to perform,
to reuse it after applying advice (at least the mapping of names)

- implement implication statements and collisions, of the form:
cond1 && ... && condn => concl
cond1 && ... && condn =(proba)=> concl
they add concl to the known facts when cond1, ..., condn
are present.

21) work on forward secrecy (dynamic corruptions)
   -> improve the proof of secrecy, to allow proving secrecy of some cells of an
   array, even if other cells are leaked.
   - in simplify, expand find in conditions of find even if the inner find
   is not unique, when the outer find is unique. The resulting find is not 
   unique.
   - examples-1.28-converted/nd/test/signedDH-forward-secrecy4.cv requires a distinction
   depending on the order in which variables are defined.
   DONE 21/7/2015
   - signedDH-forward-secrecy3.cv [No longer found!] additionally requires
   an extension of the proof of secrecy, to support
      if .. then out(c, s) else let secret = s
   that is, some cells of s are secret, others are leaked.
   Show that the usage of s[i] in which secrecy is required cannot
   be executed for j=i when s[j] is leaked. Some similarity with
   Simplify.CompatibleDefs: Simplify.CompatibleDefs tests
   compatibility between two program points ("defined" test and 
   variable definition); here we would also like to test compability
   between two program points (s used as secret and s leaked).
   DONE 28/7/2015

22) prove the AuthA protocol:
   - simplified version in which I split the hash function H into 
     3 hash functions (see examples-1.28/nd/notest/AuthA-split-hash.ocv).
     Needs an extension of "move array" in which the equality
     test is replaced with any function f(X,z) such that when
     X is a fresh random number, f(X,z) = g(z) up to small proba.
     The same extension could also be applied to ROM_hash and
     ICM_encrypt (PRF? SPRP?).
   - normal version (see examples-1.28/nd/notest/AuthA.ocv) additionally needs
        - case distinction depending on the order in which variables 
        are defined
        - improvement in simplification: CryptoVerif does not orient
        some equations...

23) Support for equations:

- example examples-1.28/nd/Herzog-encryption-modes/non_terminating/cbc_mac.ocv
           @4_r2_62 <-R block;
           @4_x_61: block <- xor(@4_r2_62, b2_44);
           find [unique] @i_67 = @ri_66 <= N_ver suchthat defined(@4_x_61[@ri_66], @4_r2_60[@ri_66]) && (@4_x_61 = @4_x_61[@ri_66]) then
	   ...
	   else @4_r2_60 <-R block
The test @4_x_61 = @4_x_61[@ri_66] always fails:
 * @ri_66 cannot be equal the current index, because @4_r2_60 is not defined yet
 * when @ri_66 is not equal to the current index, 
@4_x_61 = @4_x_61[@ri_66] means 
@4_r2_62 = xor(b2_44, xor(@4_r2_62[@ri_66], b2_44[@ri_66]))
and the RHS does not depend on @4_r2_62 (because it is chosen after the
other elements are defined)
so the collision can be eliminated.

There are also collisions that should be eliminated in the example
examples-1.28/nd/Herzog-encryption-modes/non_terminating/ccm_one_block_cpa.ocv

3/7/2015: I improved elimination of collisions. It works for NSSK,
but not for these examples...
6/7/2015: This particular collision is eliminated with
crypto aes_enc
SArename @4_x_61
The current reasoning done by CryptoVerif is as follows:
   After SArename, the collision becomes @4_x_100 = @4_x_100[@ri_66]
   and we know that @4_x_100 = xor(@4_r2_62, b2_44).
   (The SArenaming is necessary to have that, because there are
   other assignments to @4_x_61 with a different formula.)
   By replacing @4_x_100 with its value and rewriting we get
   @4_r2_62 = xor(xor(@4_r2_62[@ri_66], b2_44[@ri_66]), b2_44)
   The elimination of collisions distinguishes two cases.
   When @ri_66 is different from the current index, the RHS does not
   depend on @4_r2_62, so we can eliminate the collision and transform
   the equality into
   (@ri_66 = current_index) && (@4_r2_62 = xor(xor(@4_r2_62, b2_44), b2_44))
   that is
   @ri_66 = current_index
   which requires defined(@4_r2_60[current_index]), which is impossible.
It would be possible to eliminate this collision without doing the
SArename, by reasoning as follows:
   Inside the dependency analysis (DepAnal2), notice that @ri_66 
   cannot be the current index, because it would require
   defined(@4_r2_60[current_index]), which is impossible.
   From that, infer that @4_x_61[@ri_66] must be defined before
   @4_r2_62, so @4_x_61[@ri_66] does not depend on @4_r2_62.
   Hence the equality @4_x_61 = @4_x_61[@ri_66], that is,
   xor(@4_r2_62, b2_44) = @4_x_61[@ri_66] implies
   @4_r2_62 = xor(@4_x_61[@ri_66], b2_44)
   and the RHS does not depend on @4_r2_62.

A simpler version would be to show that CBC-MAC is a PRF, see
examples-1.28/nd/Herzog-encryption-modes/non_terminating/cbc_mac_prf.ocv
but even that is hard! (One needs to eliminate collisions between
b1 and xor(tag1[i], b2[i])...)
Improving global dependency analysis by using term simplification
in Transf_globaldepanal.almost_indep_test could help.

After improvement in elimination of collisions, the following example
is slower:
PROTOCOL examples-1.28-converted/nd/test/needham-schroeder-pk3  OK
Slower: old=2.030 new=28.202

- possible case studies:
  * OAEP, ZAEP and variants
for the proof that OAEP is IND-CCA2:
It seems to need an extension of "move array" in which the equality
test is replaced with any function f(X,z) such that when
X is a fresh random number, f(X,z) = g(z) up to small proba.
This extension could be applied directly to the ROM.
This function cannot currently be written directly in the LHS
of an equivalence because it uses pattern matching.
See examples/obasic/OAEP.ocv
  * SK3 V. Shoup and A. Rubin. Session key distribution using smart
cards. In Advances in Cryptology, EUROCRYPT, volume 1070/1996 of LNCS,
pages 321–331. Springer, 1996
  * NSL-XOR (cf
   http://www.infsec.uni-trier.de/publications/paper/KuestersTruderung-arXiv-0808-0634v1-2008.pdf)
  * CCA API (cf same paper as above)
  * RA. Bull and D. Otway. The authentication protocol. Technical
Report DRA/CIS3/PROJ/CORBA/SC/1/CSM/436-04/03,
Defence Research Agency, Malvern, UK, 1997.

- it would be nice to be able to say explicitly whether a variable
can be instantiated by the neutral element or not.
I think the default should be that it cannot: taking the neutral
element often leads to a useless degenerate case.

- transf_merge.ml: should I modify orient as in facts.ml?
That's not clear because the orientation function is different
and allows orienting f(...) -> f(...)

24) Currently, when applying the INT-CTXT-corrupt property, CV
considers that when the key is already corrupted, nothing
can be inferred from the success of decryption. It would in fact
be possible to strengthen a bit this property: when the arguments
of decryption other than the key (i.e. ciphertext, as well as
associated data and nonce if any) do not depend on the key,
we could apply the INT-CTXT-corrupt property as if the key were
not corrupted yet. Intuitively, independence shows that
we can reorganize the code so that the decryption occurs
before the corruption.
(This remark comes from the proof of correctness in wireguard.)
The same remark applies to other corruption cases.

25) For SPRP block ciphers, tell the system that collisions between
random numbers used for generating random permutations are already 
eliminated, so that the probability of collision is not counted again
in future simplifications.

26) Handle examples encryptBR93-2(b), pfdh, 
OAEP 3-round, ... Protocol of Philip MacKenzie, CRYPTO'06...

27) Simplify the final game, in order to transform it into
an "ideal functionality", in the spirit of universal composability.

28) automatically move the event up (without crossing an input/output,
and without crossing a needed let/find) to increase the likelihood of success?

29) non-asymptotic proofs (practical security)
- obtain more elegant formulae for the runtime of the games:
I could express time of a pattern matching as a function 
of the length of the matched term. (For let, I can express
this length by building a term using Setting.get_inverse, 
but how do I express it for inputs? How can the user enter
the functions obtained by Setting.get_inverse?)
I could group terms: max/+_j time(f, M_1^j, ..., M_n^j)
becomes n * time(f, max_j(M_1^j), ..., max_j^(M_n^j))
when the terms M_i^j have the same length(f...) constructs, but possibly
different maxlength(x) subterms.
I could express everything as a function of the length of non-bounded input
variables.

30) Modify to fit the theory:
- simplify the computation of indexes in cryptotransf.ml, when the
find references variables defined by let. (optional, the current
solution is also correct)

31) Would it be better to allow several distributions for the same type?
with notations like:
         distrib D: T    declares D as a distribution for type T
                         options to say that collisions are unlikely
                         (cf [large]/[password]/[sizeN] for types)
         new x: T        chooses x (almost) uniformly in T, provided T
                         is fixed or bounded
         new x: D        chooses x in distribution D, x is of the type
                         of D
         f: D -> D'      f maps distribution D to D' (generalizes [uniform])
That requires more complicated changes in the code.
Would require changes in ProVerif to make that compatible with ProVerif.

32)   In dependency_collision_rec* (in simplify.ml and simplify1.ml),
  - should I always apply remove_dep_array_index to t1?
  - should I also apply remove_dep_array_index to the subterm t =
   Var(b,l) of t1, in order to update the list l accordingly and 
   have a function "check" that works correctly?
   --> This is not necessary in dependency_collision_rec2 because
       all elements of l are replication indices (b.args_at_creation)
       Currently, I don't apply remove_dep_array_index in
       dependency_collision_rec1/3

33) finish two "TO DO" in cryptotransf.ml, check_lhs_array_ref
(not that urgent, now that I have modified check.ml so that it
rejects equivalences not supported by cryptotransf.ml)

34) try to reduce code duplication: 
try to reduce the number of calls to build_def_process, by using
a simpler function when we just need to know if a variable is
defined by a restriction/let/... and similar usages.

35) Put the basic proba functions of polynom.ml in a separate module? (to
avoid confusion between proba fcts and polynom fcts)

36) Design a language for representing deductions of facts
in simplification (and in replace, success...). 
Generate new facts using three sources:
- the CryptoVerif deduction engine, which should be enriched
so that each deduced fact is accompanied with the corresponding
deduction (proof), and its probability
- deductions manually done by the user
- possibly deductions produced by external tools (SMT solvers?)
Have a common verification procedure for all these deductions.
Then we can handle all equational theories at the cost of manual
proofs. Manual proofs may also allow us to perform case distinctions, and
to orient equations in a way the automatic proof strategy does not
find.
The certification of the system is simplified since we just have
to certify the verification procedure.
I could then count only the eliminated collisions that appear  
in the proof, not the collisions eliminated but that did not finally
lead to a transformation of the game.

37) in case arguments of differents forms that can still collide
are given to a hash function, it may be useful to transform
automatically x = f(M1,...,Mn) where f is [compos] into 
let f(x1...xn) = x in x1=M1 && ... && xn=Mn
Partly done in srcnd/transform_compos_equal_term_into_let.diff
But, for it to work properly, I would need to improve the way
simplification handles find conditions of the form
let f(x1...xn) = x in x1=M1 && ... && xn=Mn
(Currently, this fact is mostly ignored.)
==> This problem can be solved by manually introducing a
case distinction "let f(x1...xn) = x in" in the hash oracle.

38) Proof strategy improvements:
- transmit priorities to instruct.ml, so that they can be taken into 
account for choosing between different game transformations.
(useful for automating signedDH-DDH? for automating forward secrecy?)
In signedDH-DDH.cv, with the automatic proof strategy, we apply
uf_cma(sign) rkB, then DDH succeeds (but using too many calls to the
oracles Oa/Ob that leak a/b), while we should rather apply
uf_cma(sign) rkA.
We should prefer applying uf_cma(sign) rkA although it needs advice,
rather than DDH which succeeds immediately but with bad oracles.
   We would need priorities even for transformations that succeed.
   A problem is that signatures also do not have a very good priority
   level, because Opk has priority 2 and Ocheck2 has priority 3,
   to make sure that Ocheck is preferred. Even after applying advice,
   these oracles are called, but that's not a problem for signatures.
signedDH-DDH.cv seems to work with backtracking, that's probably
a better solution (or try to get the right order using the depth
as suggested below).
- try to order the game transformations that are tried according to 
a "depth": outer crypto primitives are transformed first.
- when a crypto transformation generates several advice possibilities:
   (many transformations, high priority)....(few transformations, low priority)
  CryptoVerif tries first the option (many transformations, high priority);
  if it fails, it tries (few transformations, low priority) but this second option
  will very probably regenerate as advice the advised transformations of the
  option (many transformations, high priority), which is stupid...
- when a crypto transformation advises syntactic transformations, on the
retry of the crypto transformation, try to know which of the syntactic
transformations were really helpful, and retry with those transformations only?
- when manually specifying a crypto transformation, be able to specify the
name mapping, not only the list of names?
- apply the "User advice" (generated for instance when failing to
prove a correspondence in "success", see end of Facts.check_corresp),
for instance when I can do nothing else.
==> Anyway, I think manual guidance will not be avoided for non-trivial
examples.

=========================================================================

To prove the secrecy of a key generated by some algorithm kgen:
new r:keyseed; let k = kgen(r) in... (k may be sent/received)
we cannot use "secret k" because k may not be uniformly distributed.

We can choose a boolean b at the beginning of the game,
when k is defined, add
new r':keyseed; let k' = kgen(r') in out(c, test(b, k, k'))
and prove the secrecy of b.
If the proof succeeds, this shows that k is indistinguishable
from a fresh random key k' generated by the key generation algorithm
kgen, which is the desired property.

=========================================================================

proofs of semantic security (not only secrecy; add reveal queries DONE)
+ proofs of key exchange according Bellare-Rogaway CRYPTO'93 definition
(or some other definition?) requires mutual authentication defined using
matching conversations. Using events to make more explicit the parameters
included in the matching conversations:

role A:					role B:

event startA(param)			event startB(param)
...					...
event endA(k, param)			event endB(k, param)

k = session key.
param = _public_ parameters, part of the matching conversations

Injective correspondences:	[Bellare Rogaway, def 4.2(2)]
	endA(k, param) ==> startB(param)
	endB(k, param) ==> startA(param)

endA(k, param) & endB(k',param) => k = k' = new : Ek  [ Def 5.1(1) ]

endA(k, param) in session i1 & 			      [ Def 5.1(2) ]
endA(k, param') in session i2 => i1 = i2
k = new : Ek, k used nowhere else 
and the same for B.

The proof of correspondences relies on the fact that the definition
of some variables is guaranteed by find. So proving them should by an
easy extension of simplify.ml.

==> DONE prove correspondence assertions such as
	endA(k, param) ==> startB(param)
	endB(k, param) ==> startA(param)
	endA(k, param) & endB(k',param) => k = k'
using an extension of simplify.ml on the last game.


- optionally, have two modes in simplify.ml. One in which the substitutions
are done only to obtain at least one function symbol (it is the current
mode); one is which the substitutions are done until a normal
form is reached (this is what happened in an older version -- change
around May 23)

- TestE/Test could be considered a particular case of FindE/Find
(but that requires improving the code for FindE/Find at some
places, so that it is as good as the code for TestE/Test).

- DONE allow some backtracking (useful for Denning-Sacco and NSPK)
Looking at several examples, it seems that the right order of
applying cryptographic transformations is the reverse order of
the construction of the message:
    * encrypt-then-mac: apply the security of the MAC first
    * Denning Sacco  penc(sign(...),...) apply the security of
      encryption before that of signature.
    * Kerberos
How to formalize that in CryptoVerif? 

- DONE [give priority between several functions]
allow adding advice to the specifications of primitives.
For example, add remove_assign binder pk to the oracle
enc(..,pk,r). Such advice should be applied when possible,
but the crypto. transformation should be executed even if
this advice fails. (Do not retry executing the same advice
in this case!). Useful for public-key encryption, signatures,
one-wayness.
Or give a priority between several functions in specifications
of crypto primitives. Public-key encryption would have
 x -> new r2; enc(x,pkgen(r1),r2) as high priority
 x,y -> new r2; enc(x,y,r2) as low priority
In fact, having only the first function might be enough for
many examples!!!

- DONE When there are several definitions of a random binder, the
cryptographic transformation should advise SArename.
- DONE? [tested for commutative functions; to test for one-wayness]
the system should try the transformation without advice,
when the transformation with advice fails. (There are sometimes
some choice points, in which a transformation with advice may
be preferred but not the only way. Examples: commutative function
symbols, transformation in which a term and a strict subterms
may both be mapped to functions in the LHS of the crypto transformation,
e.g. one-wayness. When the system thinks the transformation may succeed
with advice, it does not try other possible choices.)

examples-1.28-converted/nd/test/denning-sacco-corr3Block-tryautomate.cv
	DONE follow SArename by a call to simplify

ABANDONED
Why is the first proved result of denning-sacco with backtracking displayed
twice??? Because when backtracking and returning CFailure _ without having
made a step forward, the old state is displayed, not the one after executing
state_without_proof. Problem partly solved by raising Backtrack when
execute_crypto_list would immediately return CFailure in the handler
for "Backtrack".

ABANDONED
Comparison with AVISPA (see Heinrich Hordegen's PhD thesis for
results on AVISPA).
(Done some comparison with the modular approach in CAV'09)

ABANDONED
change the default mode to [all] when there is no "new" in the
function group? ([exist] is forbidden anyway in this case.)
(Complicated for what it brings: 
- needs to introduce a "Default" value for parsing, which becomes
later either All or Exist 
- for display, I need to determine the default at each point
in order to display [all]/[exist] only when they are not the default)

DONE 
give more precise probability formulas (taking into account runtime
changes, as for one-wayness).
in progress in srcnd/default.cvl, based on:
if P <=(Pr(time))=> P', 
then !N P <=(N*Pr(time+(N-1)*max(time(P),time(P')))) => !N P'

DONE
Store whether each variable makes array accesses in the variable itself

DONE
Separer les new a du client des new b du serveur dans la definition de CDH
(pour reposer sur CDH et non sur le square CDH)

DONE
calcul des probabilites, en evitant de compter plusieurs fois
la difference entre deux memes jeux (meme s'il y a des evenements)

DONE Unicity of branches/indices of find
artjetsay/scriptsUsageNumber/Kerberos-enc-IND-CPA.cv, 
Kerberos-enc-INT-CTXT.cv: unicity of the index of find
(In two nested finds of a particular form, the index of the second
find is always equal to the index of the first one, so the second
find can be simplified out.)
!I <= N
...
find U <= N suchthat C[I,U] then
  ...
  find U' <= N suchthat C'[I,U'] then
  ...
else P'

(I,U,U' are sequences of indices)

1) C[I,I'] => P' executed at index I'
2) C'[I,I'] => C[I,I']
3) C[I,I_1] && C[I,I_2] => C[I_1,I_2] (by symmetry, also C[I_2,I_1])
Then U' = U

1) and 3) imply that, for all I, C[I,I'] is true for at most one I'.
Indeed, suppose C[I,I'] is true for 2 I', I'_1 and I'_2.
When we execute the second of those, say index I'_2, C[I'_2, I'_1]
was already true by 3), so P' was not executed at index I'_2
(semantics of find), so by 1), C[..,I'_2] is wrong. Contradiction.

For Kerberos-enc-INT-CTXT.cv, we need to generalize that to several
branches of find.

A perhaps slightly less elegant but easier way: have a marking to
record that a unique branch/index of find may succeed; set it in
particular in the definition of hash functions, pseudo random
functions, and block ciphers; and keep it through game transformations.
When the branch/index is unique, we can activate further simplifications:
- if one branch is proved to succeed for some index, we can remove the 
other branches and fix the value of the index, thus removing the find.
(this is the case above when C[I,U] => C'[I,U'] and the inner find is
marked "unique"; this is also the case when the condition of a branch
of find becomes empty)
- we can merge some branches of find when they share the same code,
even if all branches do not share the same code. (Since the branch
that succeeds is unique, the merging typically occurs between a then branch 
and the else branch.)
DONE

- FIXED see examplesnd/test/bugsimplif_find_index1.cv  
- FIXED remove useless "defined" conditions (it is not enough that the
"defined" condition is known to be true, we must require that the same
"defined" condition occurs syntactically above, to preserve the invariant
that all variable accesses are under a corresponding "defined" condition)
     The "defined" condition above a program point are stored in 
     n.def_vars_at_def. The variables defined syntactically above 
     a program point are computed by "get_def_vars_above n"

- FIXED by forbidding new in conditions of find. (When new does not occur
in conditions of find, variables defined in conditions of find cannot be
referenced at positions in which their number of values matters.)
simplify.ml: fix bug in the computation of probabilities for elimination 
of collisions, for terms that occur in conditions of find and contain variables
defined in this condition of find (see examplesnd/test/bug-simplify-proba-in-find-cond*.cv)
This bug is new because it did not occur when conditions of find do not
contain if/let/find/new.

DONE added #O for the number of different calls to oracle O
problem to express random self reducibility: what's the probability 
difference for CDH? (there is probably a problem to express it in 
CryptoVerif, like for the proof of JS Coron for FDH...)
I need new parameters to express it precisely.

DONE
preuve de JS Coron pour FDH:
- refaire une preuve plus precise de la onewayness, qui donne deja
la probabilite reduite. Pour cela, utiliser #Ox pour designer 
"le nombre de x pour lesquels Ox a ete appele" dans la formule de
proba de one-wayness, et ensuite ce nombre deviendra q_S + 1 (alors que
le nombre de x est q_S + q_H + 1).
- voir aussi http://people.csail.mit.edu/dodis/ps/claw.ps
(reference donnee par Phong Nguyen)

FIXED 27/12/2009
Note that the trick of taking the max between the branches of
if/let/find is not always correct. (see
examplesnd/test/bug-cryptotransf-count-find-with-max*.cv)

DONE 29/12/2009
Merge syntax.ml and osyntax.ml

DONE 25/01/2010
remove events when they are not present in the queries.

DONE 25/01/2010 I apply the quick fix, seems good in practice.
Note: I think the way I prove correspondences with some public variables
is wrong. Currently, the public variables are not explicit, I use
secrecy queries to mention them. However, after the secrecy query is proved,
they disappear, which is not correct if the correspondences are not
proved yet. I should mention them explicitly in the correspondences.
Moreover, when I introduce an event, it should inherit the public
variables of all present queries.
A quick fix is to compute the public variables at the beginning from
the secrecy queries, and keep the same set of public variables
even when some queries are proved.


Simplify:
intersect_list may raise Contradiction 
-> add_def_vars
	get_def_vars_at
	add_def_vars_with_subterms OK
		filter_def_list OK
   add_facts
	facts_from_defined OK
	get_facts_at OK
	collect_facts OK

- DONE added setting [noninteractive] for parameters. When present, try
to remove that parameter, even at the cost of adding other parameters

- DONE 29/03/2010 give a warning when "[unique]" appears in the
initial game (because these indications imply invariants that may
not hold) 

- DONE 4/4/2010 extension for DDH: allow events in the RHS of equivalences.
For protocols such as SSH, IPsec, TLS that generate
keys with h(g^{ab}), it would be possible to prove them with DDH
plus the assumption that h transforms a random element of the group G
into a random key. (That would avoid the Random Oracle Model.)

DONE 
- when no query is given in the input file, display the probability of 
distinguishing the last game from the first in the end.

- require that all restrictions are independent but take into account
the case in which they are not by 
   if [equalities of indices that make restrictions dependent] then
   old term else new term
Be careful about loops in this case! (The old term still occurs.)
If "new term" is "false", I can write:
   [equalities of indices that make restrictions dependent] && old term
Note: "new term" is not always false, see e.g. collision-resistant
hash functions.
The old term very often simplifies when these equalities hold.
For this to work for the collision of products in CDH, we need
mult(x,y) = mult(x,y') => y = y' because the [equalities of indices
that make restrictions dependent] may equate just one of the factors.
DONE, change tech report accordingly.

DONE 9/7/2010
- make sure that we never refer to the length of a bounded type

DONE 13/7/2010
- improve the display of probability formulas by grouping terms that
contain the same Proba(f, l)
- improve simplification with division in probability
   formulas,e.g. 0/|hasht|
   DONE for the case in which appeared (encryptBR93-1)
   Could perhaps go further by decomposing Div(x,y) into
   Mul(x,Div(1,y)) and further decomposing y when it is a product
   or a division (in probaf_to_polynom). 
   The polynoms would then reorganize the formulas
   and, in the end, one should again group terms (e.g.
   Mul(x,Div(1,y)) becoming Div(x,y) for simpler display)


0) DONE Extension of mergebranches
For merge_arrays:
- allow several variables in each branch
- introduce a new variable in each branch, on which are going to make
only "defined" tests, to be able to merge arrays even if sometimes
I need to distinguish the branches.
- also merge findE

For the merging of branches that comes from simplify:
- allow simultaneous merging of branches in various finds
in the game (this allows to ignore the conditions of those
find when testing whether variables have array accesses)

0.1) DOES NOT REALLY WORK (at least for EKE: the moving of new that
   have array references must be done in a specific order, and it is
   not easy to guess it)
Automate more the moving of new that have array references.
- Apply the transformation
equiv !N new X:G; (!N2 OX() := X, 
                   !N3 Oeq(X':G) := X' = X)
<=(#Oeq / |G|)=> [manual]
      !N (!N2 OX() := find[unique] j<=N2 suchthat defined(Y[j]) then Y[j] else new Y:G; Y,
          !N3 Oeq(X':G) := find[unique] j<=N2 suchthat defined(Y[j]) then X' = Y[j] else false).
automatically when X is defined by new X and used in its definition
block.
- set mergeArrays = true when we apply the transformation above.


EKE:
- DONE consider not only secrecy of keys, but semantic security and 
authentication. Since authentication is unidirectional, we should
show the secrecy of sk_u and correspondences (6) and (7) of [CSF'07].
- final reasoning step to show that Pr[bad] is bounded (may be hard!)
    1) DONE eliminate spurious comparisons with the password, through 
   improvements in mergebranches.ml
    2) DONE[still needs some improvement, cf eke/EKEtryfinalstep] 
   improve the computation of probabilities when eliminating
   collisions on the password 
   (find j<=N suchthat defined(x[j],y[j]) && x[j] = x0 && y[j] = pw ...
   compares pw with a single y[j] when the value of x[j] determines j, 
   which is true when x[j] is a large random number).
- I also need to optimize carefully the counting of calls to oracles:
    1) DONE find @i_762 <= NP suchthat defined(x1_684[@i_762], x2_683[@i_762], Xp[@i_762], Yp[@i_762], xp[@i_762], yp[@i_762], r_679[@i_762]) && otheruses(r_679[@i_762]) && ((x1_69 = x1_684[@i_762]) && ((x2_68 = x2_683[@i_762]) && ((x3_67 = Xp[@i_762]) && ((x4_66 = Yp[@i_762]) && (x5_65 = exp(g, mult(xp[@i_762], yp[@i_762])))))))
    tests x5_65 = exp(g, mult(xp[@i_762], yp[@i_762])) for
    a single value of @i_762 because x3_67 = Xp[@i_762] (or x4_66 = Yp[@i_762]) determines @i_762
    and similarly for other finds in the hash queries
    (similar to the optimization of the computation of probabilities
    when eliminating collisions on the password above)
    2) DONE[could be extended by using "defined" conditions]
    The various finds in hash queries exclude each other because 
    of incompatible defined conditions or because the values of x3_67/x4_66
    cannot be equal to exponent generated at different points (after eliminating
    collisions among these exponents)
    3) PARTLY DONE
    the CDH queries in client/server code are all equivalent to
    queries also done in the hash oracle (perhaps reexecuting the hash oracle
    when the CDH queries is done).
   ==> There are (qH0 + qH1) CDH queries 

DONE 6) keys as arguments of events
examplesnd/JoeKaiTsayBasicKerberos_ASandTGhalf_070606a
	currently, arguments of events must not contain keys on
	which we want to apply game transformations. That's a bit too strict.
related to Ricardo's complaint:
"When verifying secrecy on a script that has events (where the secret
may occur), CV fails to find a proof. If I remove the events then
everything goes fine.... so currently I'm duplicating the source
files, but it'd nice not to have to do that."
One solution: add an indication [unchanged] near a restriction new r
in the LHS of equivalences, when r appears with the same value in the
RHS. In this case, r can be used in the arguments of events, and is
left unchanged by the crypto transformation.

- idea to improve elimination of collisions:
  give probability terms that are acceptable (e.g. currently, we
   accept "any term/|large|").
   We could accept "small/|passwd|" or "any^2/|large|"
   (but not cubes).
   Instead of annotations large, noninteractive, passwd, we could use
   Tsize0 = small types (no annotation)
   Tsize1 = passwd
   Tsize2 = large
   and more, for types.
   Psize0 = small parameters (no annotation)
   Psize1 = passive sessions (not supported now -- in a password-based
            protocol, we can have more sessions under passive attacks
            than sessions under active attacks)
   Psize2 = noninteractive
   and more, for parameters.
   In a formula p1*...*pn/|T|, parameters of smaller size are
   preferred. The formulas that give acceptable probability terms
   would use "Psize_i/Tsize_i", e.g. "Psize0/|Tsize1|" or
   "any/|Tsize2|"
   Words (passwd, large, noninteractive) are perhaps still more 
   intuitive than numbers.
   DONE
   DONE something similar for probabilities coming from "collision" statements (Proba.add_proba_red)

- simplify coll_elim <occurrences> will often not work because
  occurrences are modified internally before being tested by 
  Proba.is_large_term
  DONE 30/7/2011
  Fixed by preserving occurrences in Terms.copy_term and Terms.copy_term3.
  UNDONE 2/8/2011 in Terms.copy_term3 because it slowed down a lot
  otway-rees3Block and otway-rees3BlockTag (see above)
  REDONE 3/8/2011 by preserving occurrences but clearing facts.

DONE - separate dependency_collision1 as a special transformation
      Was very slow for otway-rees3Block and otway-rees3BlockTag.
      To speed up, I try global dependency analysis immediately
      instead of advising it. If it fails, record failure to avoid
      retrying, and continue simplification. If it succeeds, restart
      simplification with the game returned by global dependency analysis.
EKE:
- separate the global dependency analysis (DepAnal1) from
   simplification, and replace terms with their simplified form
   in the dependency analysis.
This would avoid to rely on the fact that the comparison with the
password occurs *after* the conditions that limit when it is executed.
Currently
   find j<=N suchthat defined(x[j],y[j]) && x[j] = x0 && y[j] = pw ...
   compares pw with a single y[j] when the value of x[j] determines j, 
   which is true when x[j] is a large random number.
works better than 
   find j<=N suchthat defined(x[j],y[j]) && y[j] = pw && x[j] = x0 ...
(The simplification makes a call to the dependency analysis
in Facts.add_fact for eliminating y[j] = pw before adding x[j] = x0
so x[j] = x0 is not taken into account in that call to dep.anal.)

DONE 3/8/2011
   * for each usage of build_term2, check that facts can really be preserved;
   otherwise, change it into build_term or build_termo
   => Fixed: build_term2 no longer keeps the facts

DONE 4/8/2011 cleanup separation between simplify1 and simplify

add "let f(x1'...xn') = x in P else P" at the beginning of the
hash function. In simplification, introduce "elselet" facts of the form
"forall x1'...xn'.f(x1'...xn') <> x" in the else branch of the let,
to be able to simplify the find in P.
DONE

DONE 4/8/2011
- allow changing Settings.tysize_MIN_Auto_Coll_Elim
  and Settings.tysize_MIN_Manual_Coll_Elim by a "set .. = .." instruction.
  In syntax.ml, register move_array for all types, since the size above 
  which we allow elimination of collisions may be modified.

DONE 5/8/2011
- fix bug: see examplesnd/otest/insertbug
  insert occ "let pat = t in"
  may cause an internal error in subsequent transformations 
  if pat uses twice the same variable. 
  This instruction should be rejected.

DONE 5/8/2011
- the indication [decompos] seems to have bad effects 
  (see examplesnd/Aizatulin-RPC.parse.cv), ignore it.
I replaced
  not (match t2.t_desc with
    FunApp(f,_) when (f.f_options land Settings.fopt_DECOMPOS) != 0 -> true
  | _ -> Terms.refers_to b t2)
with 
  not (Terms.refers_to b t2)
in orient in facts.ml and mergebranches.ml	

DONE 5/8/2011 Chosen Phash(time)
For collision-resistant hash functions, Phash or Phash(time)?

DONE 9/8/2011
allow to give a name to equivalences, so that one can indicate
precisely in manual proofs which equivalence to apply.
Difficulty: for equivalences given in macros, either pass the name
as argument (but that's boring, especially when these equivalences are
not used), or how to obtain the name for the expanded macro?
(Recall that each macro may be expanded several times and we should
distinguish the various generated equivalences.)
One solution: give a name of the form "name(f)", where f is a function
symbol declared in the macro, given as argument to the macro.
Since there can exist at most one definition of f, we are sure that
name(f) will be instantiated to a different name for each expansion
of the macro. 

optident:
        IDENT
        { Some ($1) }
|
        { None }

DONE 14/8/2011 partly by improving the algorithm, partly by
limiting the number of allowed pieces of advice
- avoid the combinatorial explosion when computing advised instructions
in cryptotransf.ml (cf examplesnd/Michele-signedDHv3.txt)
- document 
> let max_advice_possibilities_beginning = ref 50
> let max_advice_possibilities_end = ref 10

DONE 22/8/2011
- make more checks in cryptotransf.ml when considering subterms of the LHS,
to improve the quality of advice. (see TO DO in cryptotransf.ml)

DONE 23/8/2011
- the current definition of CDH/DDH does not allow A to talk to himself,
even if there is a check to make sure that one does not compute g^(a.a)
for the same a. The problem is that CryptoVerif transforms only g^(a.b)
when a and b come from different restrictions...
NO, that's not true: it works ok if the client role and the server
role are implemented in distinct processes, one generating a, the other
generating b; they can use the same identities and public/private keys
provided one cannot mix client and server messages, which could lead
to attacks.

DONE 24/8/2011
- when "success" advises some transformation that does not yield to proving
more properties, undo it

DONE 26/8/2011
- when I eliminate collisions with an assumption on the order of 
  definition of variables (for proving unicity of find), this assumption
  should appear in the information stored in Simplify1.term_collisions

DONE 14/9/2011
[unique] is back, with a slightly different meaning:
when find[unique] is executed and several suitable values are
found, an event "not_unique" is raised.
We have the invariant:
Pr[C[G_0] : D] \leq p + \Pr[C[G_n] : if an event among "not_unique"
   and the Shoup events is executed, then
       - if the first of these events is "not_unique", false
       - otherwise true
   else D]
where p is sum of the probability differences accumulated in
previous transformations.

DONE by David
- tables of keys

DONE 24/9/2011
- reduce the variable numbers (for instance, when a crypto
   transformation fails, the variables it generated will not be used,
   so we can restart the variable counter to the beginning of the
   transformation; the variables generated in success also need not be kept.)

DONE 24/9/2011
- try to preserve more occurrences in simplification, so that occurrences can
  still be found in the initial game even after some passes of simplification

DONE 25/9/2011
- expand get/insert: mention expansion of tables without insert in
  the detailed description of the transformation (they are omitted now)

DONE 25/9/2011
- occurrences in increasing order from start to end of the process

DONE 25/9/2011
- indent correctly even when some occurrences are displayed (and others not)

DONE 26/9/2011
- displaytex of the detailed transformations 

DONE 26/9/2011
- document briefly the detailed display and its limitations

DONE
- Implement a real cryptography library (partly done)
- Bug? You don't check that the size of the bitstring matches the 
announced size (in bitstringp, sizep...). (not relevant anymore)
- Bug? In output_bitstring, you don't output the size => you support
only sizes multiple of 8. Either you need to support all sizes, or to
guarantee by typing that the size is a multiple of 8 (and for safety, 
raise an exception if not). (ok)
- Verify that all branches return the same oracles when
generating implementations. (ok)
- Documentation: document the generation of implementations (tables/letfun
already documented)
- Use a more clever representation of types: give a Caml
  representation for each type, with associated predicates, 
  serialization/deserialization functions 
     - Exception when deserialization fails (ok)
     - We use (=) and (<>) for comparing bitstring. This implies that
       the Caml types used for representing bitstrings must not have
       cycles and must have a single representation for each bitstring.
       That's ok, but these constraints will have to be made explicit
       in the documentation.
     - Treat the case in which the predicate always returns true
       specially, for example by naming the predicate "always_true"; 
       don't make a test in this case.
     - Try to use Caml constants for constants instead of functions
       fun () -> cst???? May cause problems with functions
       letfun f() = new r:T; M(r) which must be translated to Caml
       functions. What about host_name?
       Suggestion: 
           implementation const id = "Caml constant" 
             for constants to be implemented by Caml constants
           implementation fun id = "Caml function"
             for constants to be implemented by Caml functions with
             unit argument
       ==> Done; generalized parsing of strings to allow \" and other
       escape codes. Did you catch the exceptions IllegalEscape,
       UnterminatedString correctly? Did you write this code yourself
       or copy it from some other program?
     - Interface compatible crypto_dbg/real
     - Suggestion of syntax (I'm not completely happy with it yet,
       so leave as it is for now): 
       implementation type <type name>: <comma separated list of options>
       <option> ::= size = <n> | repr = <caml type> | pred = <caml predicate>
                  | serial = <serialization function>
                  | deserial = <deserialization function>
       Pb: I would prefer to have a single option for serial/deserial,
       but then it is not clear what the syntax of this option should be
          serial = <serialization function> <deserialization function> ?
          serial = <serialization function>, <deserialization function> ?
       (in the last option, the comma mixes with the comma separated list
       of options)
       implementation fun <function name>: <comma separated list of options>
       <option> ::= impl = <function> | inverse = <inverse function>
       Not really satisfactory (impl always required, heavy to have an option
       name for it).

       Other suggestion: 
       implementation type <type name> = <size>[,<serialization function>,<deserialization function>]
       implementation type <type name> = <caml type>,<caml predicate>[,<serialization function>,<deserialization function>]
       The drawback is that there is no explicit indication of the meaning 
       of each element; with 4 elements, that starts being complicated.

       implementation type truc = 8;
                      type true = "Camltypename" [serial = "s","d"; pred = "p"];
                      fun f = "Camlf";
                      fun f = "Camlf" [inverse = "Camlinverse"];
                      const c = "Camlc";
                      table t = "File".

DONE
SSH:
- prove security of KC/KS and h
- server and client talking to dishonest interlocutors
- constructIV/EK/MK more detailed (so that there is a security
  assumption on them)
- detail the encryption scheme?
- prove SSH; may require using a distinction depending on the
  order in which variables are defined

DONE
2bis) Generate implementations from the abstract model
references of related work on this topic:

Pozza, D., Sisto, R., Durante, L.: Spi2java: Automatic cryptographic protocol
java code generation from spi calculus. In: International Conference on Advanced
Information Networking and Applications. (2004) 400-405

Tobler, B., Hutchison, A.: Generating network security protocol implementations
from formal specifications. In: Certification and Security in Inter-Organizational
E-Services, Toulouse, France (2004)

DONE
- for examples/woolamskcorr_tbl2.cv with processK:
let processK =
        in(c10, (Khost: host, Kkey: key, Kmkey: mkey));
        get keytbl (x,y,=Khost) in yield else
           insert keytbl (Kkey, Kmkey, Khost).
infer standard facts from elsefind facts with all defined conditions true 
(or no defined condition at all).
==> solved with a manual "replace" (thanks to get_facts_of_elsefind_facts)
or with "set elsefindFactsInSimplify = true."

DONE Updates to eprint 401
    * section D.2.3 Relaxing H6:
We need to make sure that the needed variables are defined after
the transformation. To do that, we establish a correspondence between
the restrictions before the transformation and the restrictions after, such
that, as far as possible, if a variable is used in a transformed expression,
the corresponding variable before transformation is also used in the
initial expression. For variables that appear in a transformed
expression but are not used in the initial expression, we check
when performing the transformation that they will correctly be
defined. (Bug fixed in CryptoVerif 1.09) [DONE]

    * Delete "otheruses" [DONE]

    * section D.2.4 Relaxing H'2 should be fixed.
        ** Since expressions in a condition of find are evaluated as 
many times as the find indices, we must forbid transformation when the
LHS is new a; (...) -> M without replication under new a, and the
transformed expression is in the condition of find and depends 
on the find indices
(and new a is not in that condition of find, but the latter point
is always true since we transform conditions of find only when they
do not contain if/let/find/new). [FIXED]

    * Update definition of the Random Oracle Model,
add definition of the Ideal Cipher Model

    * SPRP: e, d -> enc, dec
UF-CMA sign: c,s -> check, sign

    * in section D.2.2, I could add [useful_change], [manual], and priorities. 
(This is not bug fixing, it's a new feature.) 

    * Added SUF-CMA signatures, Updated the definitions with the current model of default.cvl
    * Add IND-CPA + INT-CTXT, IND-CCA2 + INT-PTXT shared-key enc

    * Next change is important: the definitions of primitives now use it!
in section C.1, collisions now consider that the restrictions
are all independent. The algorithm has to be adapted:
Suppose M rewrites into M' provided restrictions r1[~M_1]...rn[~M_n] are
independent. We collect conditions: 
    { C_k } = { ~M_i = ~M_j | ri = rj for i<>j }, 
If there are no such conditions, it's ok: the restrictions are always
independent. Otherwise, M should in fact be rewritten into:
    if \vee_k C_k then M else M'
We handle only the case in which M' = false. In this case, the
expression is equal to
    (\vee_k C_k) \wedge M
that is
    \vee_k (C_k \wedge M)
We simplify M knowing C_k, into M_k. If we always manage to simplify M,

we rewrite into
    \vee_k (C_k \wedge M_k)
Otherwise, we do not perform any transformation, because maintaining M
would lead to a loop, in which we might try applying the same transformation
again to M.

   * Extend a little bit the explanation of 
CompatibleDefs.check_compatible_deflist (page 27, col 1):
replace "x[N1...Nl] is a subterm of Mjk" with "defined(M) \in {\cal F}_{Pj}
and x[N1...Nl] is a subterm of M".

    * Second item of Appendix C.6: add the condition that 
M_{j1}, ..., M_{jl_j}, M_j make no array accesses to u_{jk}
(with indices different from the current indices)

    * p 27, col 2:
Add the explanation of CompatibleDefs2.check_compatible2_deflist.

    * Update the move_new transformation to include
- move "new x" even when x has array references, but only inside
the same output process.
- move "let x = t in" when x has no array references and the let
can be moved under a if/let/find in which x is used in a single branch.
(The term t is then computed in fewer cases.)

   * Mention the fact "forall x. pat != t" in the else branch of
   let pat = t in ... else ...? (That will be informal, since
   "let pat = t" is not included in the calculus formally studied.)

   * Should I document that global dependency analysis is now
   a separate transformation from simplify? (which can be called
   internally from simplify; the difference is that it updates the whole
   game instead of just recording that some terms are different)

FIXED bug in examplesnd/test/bugCV1.15-new-in-get.cv

FIXED 16/7/2012 cryptotransf.ml
(* TO DO the indices one_exp.cur_array_exp are not correct when 
there is a find in the condition of a find. Either fix this problem by
passing cur_array as an additional argument to instantiate_term,
or forbid find in condition of find in the RHS of equivalences. *) 

FIXED 16/7/2012 
src/facts.ml:   (* TO DO The test List.memq f l always fails
==> use List.exists (Terms.equal_terms f) l instead

DONE 16/7/2012
When an else branch of a term cannot be executed, replace it 
with a constant

DONE 16/7/2012
src/insertinstruct.ml, replace, FindE case: add facts coming from elsefind facts, 
as in the Find case

FIXED 16/7/2012
In reduce_tables, there is a bug if I make array accesses
to variables bound by get (I substitute them without
being really careful, in get_find_branch_term/get_find_branch_process)
See examplesnd/test/bugCV1.15-array-access-get-vars.cv

DONE 17/7/2012
In Check.update_def_list_term, case FindE, it may be more logical to
use Terms.close_def_subterms rather than Terms.get_deflist_subterms.
But check which terms can actually occur in def_list.
(What happens if def_list contains "b[if M then j else k]"?)
==> def_list cannot contain "b[if M then j else k]", this
is forbidden by syntax.ml, check_no_iffindletnewevent
It may even not be necessary to consider the subterms of def_list,
since update_def_list_term is called only in the RHS of equivalences,
and there def_list has a very specific form b[indices].
==> Fixed in check.ml, same remark in transform.ml (but slightly more
   complicated to modify, I can perhaps leave as it is in
   transform.ml)
Code to compare the old computation with the new one:
	    let def_list_subterms2 = ref [] in
	    List.iter (fun (b,l) -> 
	      Terms.add_binderref (b,l) def_list_subterms2;
	      List.iter (Terms.get_deflist_subterms def_list_subterms2) l) def_list;
	    if not ((List.for_all (fun br -> List.exists (Terms.equal_binderref br) (!def_list_subterms)) (!def_list_subterms2)) &&
		    (List.for_all (fun br -> List.exists (Terms.equal_binderref br) (!def_list_subterms2)) (!def_list_subterms))) then
	      print_string "CHANGED LISTS!!!\n";

DONE
* New semantics of find:
Change Terms.binder_from_term into Terms.repl_index_from_term
       Terms.term_from_binder into Terms.term_from_repl_index
when needed
Check usages of Terms.copy_term,
   Terms.subst (substitutes repl indices, not vars)
   and other copy functions.
   Integrate Transform.rename_term and Transform.copy_term into
   Terms.copy_term.
Removed field future_def_vars -> done
Removed Terms.is_repl -> done
In Find, add the find indices (that are replication indices) to cur_array
for def_list and the condition. Warning! Once I do that, it is no longer
true that the replication indices inside an array access are a suffix
of cur_array (they may also be indices of find, which are not at the end
of cur_array).

DONE 17/7/2012
src/facts.ml: merged the two variables seen_refs and def_vars_accu

DONE 18/7/2012
src/transform.ml: transformed rename_XXX into a case of Terms.copy_XXX

DONE 18/7/2012
src/transform.ml: transformed the function Transform.copy_process into a particular
case of Terms.copy_XXX

DONE 19/7/2012
Added a warning "identifier rebound", like in ProVerif.

DONE 19/7/2012
Explain new semantics of find in the manual.

DONE 29/7/2012
- allow to generate random numbers for any finite type (BOUNDED).
However, distinguish two cases:
   - for FIXED types, the random number generation is exact, as
   currently. It runs in time time(new T).
   - for non-FIXED types, we have two random number generations:
      - the exact one, which may take unbounded time
      - an approximate one, which returns the same result as the exact
      one up to probability \eps_T, and runs in time time(new T, \eps_T).
   CryptoVerif code always uses the approximate one. But
   the specifications of primitives, in their formulas, take into
   account that the underlying computational assumption relies on the
   exact random number generation, so they take into account
   probability differences \eps_T.
   We can avoid displaying the terms depending on \eps_T except if we
   ask for a very precise display of probabilities.
In fact, we can even allow non-uniform distributions!

FIXED 3/8/2012
   crypto uf_cma(signr) gave bad advice in ssh-secrecy-key.ocv
The crypto transformation tries all fresh names b.
   if b is defined several times and cannot be discharged, it advises
   SArename b.
   on the other hand, the terms check(.,.,.) can always be discharged,
   so it thinks that the transformation with b is useful.
   Therefore, the advice is kept, even if b has nothing to do with signatures!

DONE 3/8/2012
- generalize the implementation of simplification so that it can 
  be applied after a cryptographic transformation and before the
  expansion of if/let/find/new in terms. This could reduce the size
  of the expanded game (considerably in some examples, such as 
  the proof of secrecy of the 6 session keys in SSH) and speed up
  CryptoVerif.
   ==> I've modified expand so that it simplifies a bit the terms.
   That helps for SSH and otwayrees3Block. Could I do even better?
   For otwayrees3Block, doing the global dependency analysis before
   expanding the game should help. In fact, it's not that easy. For instance:
   	     	let concat2(=Nb, k) = dec(eb2, Kbs) in
   When dec(eb2, Kbs) is a fresh random number, this has a negligible
   probability of succeeding, then the fresh random number is used
   only in comparisons in other queries, so dependency analysis 
   removes this case. However, the problem is that we need to expand
   the term that replaces dec(eb2, Kbs) in order to realize that 
   "let concat2(=Nb, k) = dec(eb2, Kbs) in" fails when dec(eb2,Kbs)
   is a random number...
   SSH is still rather slow, see why.

set elsefindFactsInSimplify = false.
set detectIncompatibleDefined = false.
378.730s (user 378.160s + system 0.570s), max rss 2536000K

set elsefindFactsInSimplify = false.
381.330s (user 380.580s + system 0.750s), max rss 2563984K

set elsefindFactsInSimplify = true.
672.100s (user 671.460s + system 0.640s), max rss 2435904K

The game is very big after applying rom(h) (17682 lines). It decreases a bit
after simplification (13240 lines), but the real decrease is after 
applying uf_cma(sign) and simplifying (621 lines!). It seems difficult to avoid
expanding the game before doing uf_cma(sign)...
Swapping rom(h) and uf_cma(sign) does not significantly speed up CryptoVerif.

DONE 8/8/2012
3) guess an SArename instruction before success

a correspondence event inj:partA(B, x) ==> inj:partB(A, x)
can no longer be proved in 
authexamples/needham-schroeder-pk3BlockAuth
authexamples/needham-schroeder-pkcorr3BlockAuth
authexamples/needham-schroeder-pkcorr3BlockKeyHash !!!
(change between 29/12/2009 and 25/1/2010)
The problem is solved when I no longer expand assignments for constants
(remove | FunApp(_,[]) line 1532 of transform.ml). 
Note: I should also add | FunApp(_,[]) in expand_assign_term
(line 1413 of transform.ml)
OK, I understand: we have

  orfind @i_872 <= N suchthat defined(@1_m2_716[@i_872]) && (m_33 = @1_m2_716[@i_872]) then
  (
    let Na_1258: nonce = cst_nonce in
    let hostY: host = A in
    out(c8[!_24], (B, hostY));
    in(c9[!_24], (pkY: pkey, =hostY, ms_35: signature));
    find @i_58 <= N suchthat defined(Rkey_113[j2[@i_58]], @2_x_54[@i_58]) && ((pkY = @1_pkgen2(rkA)) && @2_check2(concat3(pkY, hostY), @2_pkgen2(rkS), ms_35)) then
    new r5_1262: seed;
    let @1_m2_226: bitstring = @1_enc2(Z, pkY, r5_1262) in
    event partB(hostY, (m_33, @1_m2_226));
    out(c10[!_24], @1_m2_226);
  .................
    orfind @i_58 <= N suchthat defined(h2[@i_58], Rkey_113[j2[@i_58]], @2_x_54[@i_58]) && (((pkY = @1_pkgen2(rkA)) && (hostY = h2[@i_58])) && @2_check2(concat3(pkY, hostY), @2_pkgen2(rkS), ms_35)) then
    (
      new r5_1260: seed;
      let @1_m2_226: bitstring = @1_enc2(Z, pkY, r5_1260) in
      event partB(hostY, (m_33, @1_m2_226));

and we know that
@1_m2_226[@i_336], @i_872[@i_336] are defined.
Since @i_872[@i_336] is defined, we get hostY = A (future fact coming
from let hostY: host = A in). Since @1_m2_226[@i_336] is defined
we get event partB(hostY, (m_33, @1_m2_226)) in all cases.
If I replace hostY with A when possible, I can no longer prove anything.
=> I'm undoing the replacement of constants for now.
In the longer term, I should perhaps improve the way facts are
collected.
In fact, a solution to this problem is to SArename @1_m2_226. If the
two resulting names are @1_m2_227 @1_m2_228, knowing that
@i_872[@i_336], we are necessarily in the branch that defines
@1_m2_227 (not @1_m2_228), so we get the result. The problem is: how
could CryptoVerif guess that it should SArename @1_m2_226?
The reason is that taking the intersection because of the several
definitions of this variable removes a key fact (event partB(...)).
(This problem may be similar to the guess of the last SArename in
examples/woolamskcorrBlock.
A similar phenomenon also occurs in examplesnd/kerberos/JoeKaiTsayPublicKeyKerberos_fixed_071120c in CryptoVerif 1.10)

I tried to solve that problem by advising (SArename b) when a useful event
is eliminated due to an intersection over all definitions of b,
in check_corresp (see srcnd/facts-advise-SArename-in-check-corresp.ml).
It finds the desired SArename advice, but finds a bit too many 
SArename suggestions, which slows down CryptoVerif.
==> To avoid that problem, the advice is not automatically applied
but displayed as "User advice: ..." That's still helpful for the user
trying to do the proof manually.
I could use the same idea at other places where CryptoVerif
has some idea what to do, but doing it gives bad results on
some examples.
In the future, I could also use that advice in the automatic proof
strategy, but for instance, only when I am blocked and can do nothing else.

DONE 10/8/2012
- improve the display of probability computations, to explain
  why sometimes events are counted once instead of several times.

FIXED 7/2/2013
- There may be a subtle bug in case a term is physically copied
during simplification. When we set the facts known that that point,
we may make mistakes in that case!

FIXED 13/2/2013
Note: examplesnd/test/Avik-luby-rackoff.CV does not work temporarily
because && and || are declared AssocCommut, which is not supported
yet. It should work again when AssocCommut will be supported.

FIXED 14/2/2013
- examplesnd/test/Avik-luby-rackoff.CV:
Internal error: Type error

SOLVED by the support for the equational theory of XOR
examples/encryptBR93-2(b): 
	Make the proof work. One needs to guide the simplification
        to avoid using menc = test(b,m1,m2), and rather use directly
        menc = m

DONE
examplesnd/test/Avik-luby-rackoff.CV is interesting for the theory of XOR.
CryptoVerif should be able to handle it without giving so
many specific equations about xor, if the support of XOR is good.

Almost DONE
Support for equations:
- Groups: I could have added rewrite rules
		   inv(inv(x)) -> x
		   inv(f(x,y)) -> f(inv(y), inv(x))
		   inv(n) -> n 
  in syntax.ml. However, these rewrite rules are not sufficient
  for matching (e.g. match M with inv(x) always works with x = inv(M);
  match M with inv(f(x,y))), so I preferred indicating the equational
  theory in function inv. There must then be a specialized procedure
  for equality, matching, ... with function inv.
- add support everywhere there is Commut
* terms: equality, DONE
   The equality test could be improved: in case we want to test
   whether (M1 = M2) equals (M1' = M2') and these terms involve
   groups or xor, we can move terms from one side of the equalities to
   the other. DONE
* transf_crypto
    - check_instance_of_rec: matching in subterms
    partly done: I still need to allow matching in subterms when a product
    occurs at the root of the considered term.
* transf_merge
    - match_term/apply_red: simplification of terms similar to
    what happens in facts.ml (but try_no_var is not applied at each step,
    terms are fully reduced from the start using function "reduce")
      ==> Now calling facts.ml instead
* simplify1
    - OK apply_statements_at_root_once: calls Facts.match_term
    - DONE match_term3: matching; used to avoid eliminating twice the same
    collisions. The variables are replication indices + a special 
    "any_term_name" 
    - DONE (functions forbidden in match_term2)
    match_term2: matching; used to match binderrefs only, so
    functions should in fact not occur. The variables that can be substituted
    in this matching are the replication indices in a list [bl].
    
* facts
    - DONE unify_terms: equality, but return a common form 
    - DONE match_term/apply_collisions_at_root_once/
      apply_statements_subterms_once/
      apply_statements_and_collisions_subterms_once: matching in subterms
    - DONE guess_by_matching: matching; variables are Var(v,[]); calls next_f()
    instead of raise NoMatch in case of matching error.
    - OK guess_by_matching_same_root: matching;  variables are Var(v,[]); 
    raise NoMatch in case of matching error.
      ==> guess_by_matching_same_root now does not use the equational
   theory, it calls guess_by_matching instead.

OK - no need to reapply Terms.apply_eq_reds just after having done it
(in Facts.apply_all_reds)
==> Actually, this is not entirely true: when simplifying M1=M2
where M1,M2 are products, we may get a term M1'=M2' that can still
be simplified (in case all products of a first kind have been
removed, and products of a second kind appear; for that to occur,
we need two kinds of products for data of the same type)
==> So I'm going to continue iterating. In that case, is it
faster to always apply Terms.apply_eq_reds to subterms, as I do?
I leave as it is, see on the tests.

- DONE check types ok before applying match_assoc/match_AC 
- DONE matching: treat specially the cases: inv(M), M' (reduce to
M, compute_inv(M')); prod, _ (use match_assoc/match_AC); =, <>
as in equal_terms
(The terms are always simplified using the equational theory before,
so if t2 is a product, it is a product of at least two terms, hence
can only be matched by a product, a variable, or the inverse of a
variable.)
- DONE matching in subterms: when M1 and M2 are both products, allow
terms before/after M2 when matching in subterms.

* orient: if an equation M = M' can be oriented neither as M -> M'
nor as M' -> M, and M or M' is a product in a group or a xor,
try to isolate each factor N of M/M' that is a variable, yielding
equation N = N' and orient N -> N'.
DONE in facts.ml. Should it also be done in transf_merge.ml?
That's not clear because the orientation function is different
and allows orienting f(...) -> f(...)

- DONE manual: mention the new declaration "equation", remove the "commut" 
function option; also mention that in the file CHANGES.

DONE 3/9/2013
considering xor(xor(M1,M2),M3) as subterm of xor(M1,M2) = M3
may be useful also in other cases (simplification of facts in facts.ml)
If xor(xor(M1,M2),M3) reduces into xor(N1,N2), 
   then rewrite xor(M1,M2) = M3 into N1 = N2
Otherwise, if it reduces into N1, then rewrite xor(M1,M2) = M3 into N1 = zero
Same thing for groups.

FIXED 3/9/2013
- There might be a bug because in Facts.apply_collisions_at_root_once,
via reduce_rec we call simplif_add, which in turn calls apply_reds,
and hence may reuse the collision we were using in
Facts.apply_collisions. Therefore, variables in that collision
may still contain links that they should not contain.

DONE 4/9/2013
- Improve "replace" so that it solves Jannik Dreier's example
examplesnd/Dreier-exemple.cv

DONE 10/9/2013
  - matching modulo does not interact well with the advice proof strategy:
we should allow a variable in the process (which will be instantiated after 
applying advice) to match several elements in the equivalence.
See examplesnd/test/Avik-luby-rackoff-corrected.CV for an example.

has_var l = List.exists (fun t ->
	match get_var_link t with
           Some (NoLink,_) -> true
         | _ -> false) l

    [is_var_inst]: [is_var_inst t] returns true when [t] is a variable
    that may be replaced by a product after applying advice.

let default_is_var_inst _ = false

let is_var_inst t =
  match t.t_desc with
    Var(b,_) ->
      if (!no_advice_mode) || (not (List.exists (function 
        { definition = DProcess { p_desc = Let _ }} -> true
      | { definition = DTerm { t_desc = LetE _ }} -> true
      | _ -> false) b.def)) then
        false
      else
        true
  | _ -> false
in


match_assoc: match_assoc is programmed like unification modulo
associativity. Indeed, variables in the pattern and variables that
may be modified by applying advice in the instantiated term
can both be considered as variables. 
There still differences with unification modulo:
- we don't put links in variables that can be modified by applying advice.
Indeed, we do not really care about the value of these variables,
they will be instantiated by applying advice.
- since the function match_term called to match individual terms
is still a matching function, we must be careful to call it
with the pattern term as first argument and the instantiated term
as second argument. So we must remember which terms come from
the pattern and which come from the instantiated term.

match_AC: when matching fails, if List.exists is_var_inst l2 then
	  delay the matching of the current term.
At the end, if there are delayed elements or the final matching of variables fails,
    - check that there still unmatched elements with is_var_inst true
    (otherwise matching fails: there is no way to match the delayed elements)
    - force advice on all elements of l2 for which is_var_inst is true
    - if allow_rest or has_var l1, then succeed
    - otherwise, check that there is no element of l2 with is_var_inst false
    (otherwise matching fails)

This definition of match_AC is organized to match as many terms as 
possible, so that something is discharged
(otherwise, the matching is just ignored even if it succeeds)
The current definition of match_assoc is not optimal in this respect.

=> These functions match_assoc and match_AC are programmed in match_advice.ml
but they still need to be integrated in the rest of the program.

FIXED 11/9/2013
* the failure of finding advice in the example 
examplesnd/test/Avik-luby-rackoff-corrected.CV
does not come from w = w[j] not matching xor(h(k,x),h(k,x')) = y
(because even if it matches with advice RemoveAssign w, it does not
discharge anything since the key k is not visible).
It comes from the definition of w: xor(u, h(k,v)) after RemoveAssign temp1
not matching a subterm of xor(h(k,x),h(k,x')) = y.
In this case, subterms of equality should be xor(xor(h(k,x),h(k,x')), y)
(do something similar for groups), and we should use something similar to
matching of subterms modulo AC (or assoc for non-commutative symbols)
except that the subterms are in the pattern, not in the instance!
=> rather enrich the instance term with variables. 
   For xor/commutative groups, the instance term is multiplied by a variable. 
   For non-commutative groups, the instance term is multiplied by a
   variable before and after. This works for match_assoc since we
   program it like unification modulo associativity. For match_AC,
   which is still programmed like matching, we keep the trick of using
   the "allow_rest_pat" argument.

Note that, while matching a sublist of h(k,x), h(k,x'), y with u, h(k,v)
seems sufficient for this example, it yields a matching
that will not correspond to the final matching: it matches
k -> k, x -> v, y -> u, and finds the advice RemoveAssign w, 
but in fact in the final matching, we will match y -> xor(u, u[j]).
With this matching of subpatterns, variables may be instantiated into 
a product which is only partly known...

DONE 6/10/2013 (David)
- on pourrait afficher un warning quand certaines hypothèses de
notre article journal ne sont pas satisfaites. Par exemple, quand
on n'a pas des bornes distinctes pour les réplications, ou qu'on a
des réplications imbriquées ou au dessus d'une composition
parallèle, on pourrait afficher un message qui indique a
l'utilisateur qu'il pourrait obtenir une probabilité plus précise
en mettant juste une réplication au dessus de chaque oracle qui
peut être répété, avec une borne distincte.

DONE 6/10/2013 (David)
- les messages d'erreur parlent de "The oracle c1..." alors que
quelquechose comme "The function that receives the messages sent on
channel c1..." serait sans doute plus approprie.
- par souci de cohérence, si on garde la version actuelle avec des
vérifications plus fortes dans implementation.ml que dans syntax.ml,
ce serait sans doute bien de faire tes nouvelles vérifications
seulement si on génère une implémentation quand on utilise le
front-end avec les canaux. Qu'en penses-tu ?

- transf_crypto, check_instance_of_rec
  - I still need to allow matching in subterms when a product
    occurs at the root of the considered term.
    DONE 12/9/2013, still to test

tested support for equations 14/10/2013

ABANDONED
- understand the change in probability formula in 
examplesnd/test/signedDH-simp
< with a, b [probability pCDH(time(context for game 26) + time, 2. * N, N * N + 
13. * N + 7. * N * nH) + 2. * N * N / |Z|]
---
> with a, b [probability pCDH(time(context for game 26) + time, 2. * N, N * N + 
7. * N + 7. * N * nH) + 2. * N * N / |Z|]
between tests/ndtest2013.02.12-12_43_43 and tests/ndtest2013.02.12-14_19_13

examplesnd/yahalom3StreamMod2 did not terminate; that's now
fixed, but an improvement of simplification could be better to
completely solve the problem
(see that file for explanation)
17/11/2013: this looping problem should be fixed, although
I did not test on this example, since the looping had already been
removed by changing the proof strategy.

FIXED 22/11/2013
- when the rewrite rule is modified by prod_orient, I should
recheck whether a contradiction can be obtained by elimination
of collisions, or even I should consider all possible separations
LHS/RHS (with one factor in the LHS) to try to obtain a 
contradiction by elimination of collisions.
I should also make sure that all factors of the product are
reduced by try_no_var (this causes the internal error reported
by Jonathan Herzog, Nov 19, 2013).

DONE 20/12/2013
- Improve simplification to orient equations with function symbols
on both sides (probably with an ordering on function symbols,
constants are the best normal form; perhaps reducing to a term with
fewer variables).
==> causes problem in proof of correspondence 
fullA(B, k, x) && fullB(A, k', x) ==> k = k'
in needham-schroeder-pkcorr3BlockKey
PROBLEM FIXED

7/1/2014
There is one case in which try_no_var does not normalize the term
(even when the rewrite rules are normalized): when the root symbol is a
function, the term is left unchanged by try_no_var, even when there is a 
rewrite rule for that term. The term should be reduced, at least before 
orienting the rewrite rule. Perhaps always? 
(Assuming the rewrite rules are normalized, 
- when the root symbol is a variable, reduce recursively the arguments,
then apply one rewrite rule at the root if possible.
- when the root symbol is a function, apply one rewrite rule at the root 
if possible. One can use try_no_var in testing whether the term is equal
to the LHS of the rewrite rule; however, try_no_var must not be applied to
the whole terms, otherwise it will lead to a loop, and it is useless.)
==> Normalizing always leads a loop.
Normalizing before orienting the rule slows down execution.
I finally decided to leave it not normalized.

8/1/2014
- Facts.orient: try variants
   - replace is_restr with is_restr && t.t_type.tsize >= 1 DONE
   - test if t1 is a subterm of t2 instead of refers_to b t2 ?
     the last case could then probably be removed. NOT DONE
   - try using an ordering on function symbols to orient rules
     FunApp -> FunApp
     Finally, I decided to orient by decreasing the size when
     the number of variables is the same.

DONE 9/1/2014
- Improve display of games with terms that are complex expressions.
Example of something badly displayed:
x:T <- y:T' <- M; M';
should be
x:T <- (y:T' <- M; M');
At each occurrence of "display_term t", decide whether t should be
between parentheses.
- Var and FunApp with non-infix symbols should never be between parentheses
- For the last term of Res, If, Find, and Let (else branch when it exists, in otherwise):
  - put parentheses around infix symbols
  - do not put parentheses around Res, If, Let, Find, Event
- For the then/in term of If/Find and Let with an else branch 
  - put parentheses around infix symbols
  - put parentheses around terms only when they may have an else branch
- For the condition of If/Find, the M in "let x = M in...",
  - do not put parentheses around infix symbols
  - put parentheses around Res, If, Let, Find, Event
- For the arguments of functions/Var:
  - put parentheses around infix symbols
  - put parentheses around Res, If, Let, Find, Event
- For the arguments of infix symbols:
  - put parentheses around infix symbols except when it is the same
    infix symbol ||, && as above
  - put parentheses around Res, If, Let, Find, Event

DONE 9/1/2014
- I added set_PD_OW in default.ocvl and default.cvl, documented it.

DONE 7/5/2015
- Code transf_expand like expansion in ProVerif (using functions)

FIXED 12/5/2015
- For files 
examplesnd/kerberos/JoeKaiTsay-PKINIT_fixed_041307_keyNOTmkey_pkeyNotspkey
examplesnd/kerberos/JoeKaiTsay-PKINIT_fixed_041507_Maceq
CryptoVerif cannot prove 
event fullC(K, k, x) ==> fullK(C, k, x), event inj:fullC(K, k, x) ==> inj:fullK(C, k, x).
This problem appeared after writing "apply_reds simp_facts t"
instead of just "t" in Facts.simplify_term_rec.
One explanation is that the additional simplifications
allowed by "apply_reds simp_facts t" remove some conditions
of a find, which were useful for CryptoVerif to prove the desired
correspondence.
However, one could also simplify the game further and eliminate
completely the branch that prevents the proof of the correspondence.
More precisely, we obtain a game containing:
           find @i_506 = @ri_505 <= N suchthat defined(m2_470[@ri_505], auth[@ri_505], s2_593[@ri_505], @i_350[@ri_505], n5[@ri_505], hostW[@ri_505], AK_692[@ri_505]) && (m21 = m2_470[@ri_505]) then
           (
	     ...
             if (!_241 = @i_350[@i_506]) then
	     ...
             let x_320: sblocksize = pad(n2) in	     
and moreover m2_470 is defined under
             find @i_350 = @ri_345 <= N suchthat defined(n2[@ri_345], x_320[@ri_345]) ...

so the condition !_241 = @i_350[@i_506], with the defined condition of
the above find, implies that x_320[@i_350[@i_506]] is defined, that
is, x_320[!_241] is defined but that's impossible at this point because it
is defined only later. Hence the test !_241 = @i_350[@i_506] is always
false. Extending CryptoVerif to use this point would solve the problem.
(That's similar to the incompatibility of defined conditions that we
apply when we simplify a "find", but it should be applied also
at other program points, here at the "if (!_241 = @i_350[@i_506]) then".)

PROBLEMS after adding try_no_var in transf_crypto (11/05/2015):
PROTOCOL needham-schroeder-pk3BlockAuth  
RESULTS DIFFER! Expected:
RESULT Could not prove event inj:endB(x, y, na, nb) ==> inj:beginA(x, y, na, nb), event endB(x, y, na, nb) ==> beginA(x, y, na, nb).
Actual:
RESULT Could not prove event inj:endB(x, y, na, nb) ==> inj:beginA(x, y, na, nb), event inj:endA(x, y, na, nb) ==> inj:beginB(x, y, na, nb), event endB(x, y, na, nb) ==> beginA(x, y, na, nb), event endA(x, y, na, nb) ==> beginB(x, y, na, nb).
Faster: old=3.310 new=1.824

==> works with SArename @15_m2_307 (given as user advice)
SOLVED by adding that as proof step.

PROTOCOL needham-schroeder-pkcorr3BlockAuth  
RESULTS DIFFER! Expected:
All queries proved.
Actual:
RESULT Could not prove event inj:endB(x, y, na, nb) ==> inj:beginA(x, y, na, nb), event inj:endA(x, y, na, nb) ==> inj:beginB(x, y, na, nb), event endB(x, y, na, nb) ==> beginA(x, y, na, nb), event endA(x, y, na, nb) ==> beginB(x, y, na, nb).
Faster: old=2.710 new=0.824

==> inj:endA(x, y, na, nb) ==> inj:beginB(x, y, na, nb)
works with SArename @15_m2_307 (given as user advice)
SOLVED by added that as proof step

it applies ind-cca2 on rkA and rkB at the same time!
applying it on rkA then rkB is possible but does not work.
applying it on rkB first always adds rkA together at the same time.
before the change, CryptoVerif applied it on rkB, then rkA.
Applying ind-cca2 on rkA and rkB is normal:
 - given the oracle enc(...) with mark [all],
 all expressions enc(...) are selected as needing to be discharged.
 - when try_no_var manages to compute the real value of the key (pkgen(rkA) or pkgen(rkB)),
 they can be discharged both by
      Oenc(x1:cleartext) := enc(x1, pkgen(r),r1)
      Oenc2(x:cleartext, y:pkey) [3] := enc(x,y,r2) [all]
 the former has priority, but that implies discharging rkA / rkB.

To prove inj:endB(x, y, na, nb) ==> inj:beginA(x, y, na, nb),

            orfind @i_527 = @ri_359 <= N suchthat defined(@15_m2_522[@ri_359], @i_332[@ri_359], Nb_254[@ri_359]) && (m_196 = @15_m2_522[@ri_359]) then
            (
              if (!_188 = @i_332[@i_527]) then
              event beginA(A, hostX, Na_259, Nb_254[@i_527]);
              new r4_487: seed;
              let @15_m1_275: bitstring = @15_enc2(Z, @15_pkgen2(rkB_278), r4_487) in
              out(c6[!_188], @15_m1_275);
              in(finish[!_188], ())
            )

          find @i_330 = @ri_329 <= N suchthat defined(@15_m1_297[@ri_329]) && (m_198 = @15_m1_297[@ri_329]) then
            yield
          orfind @i_332 = @ri_331 <= N suchthat defined(@15_m1_279[@ri_331], Na_259[@ri_331]) && (m_198 = @15_m1_279[@ri_331]) then
          (
	  ....
          )
          else
            ....
            find @i_241 = @ri_240 <= N suchthat defined(h2[@ri_240], @16_x_239[@ri_240], Rkey_246[j2[@ri_240]]) && (pkY = @15_pkgen2(rkA_308)) && (hostY = h2[@ri_240]) && @16_check2(@16_m1_238, @16_pkgen2(rkS), ms_200) then
              (
                new Nb_254: nonce;
                new r5_449: seed;
                let @15_m2_524: bitstring = @15_enc2(Z, pkY, r5_449) in
                out(c10[!_189], @15_m2_524);
                in(c11[!_189], m3: bitstring);
                find @i_312 = @ri_311 <= N suchthat defined(@15_m1_297[@ri_311]) && (m3 = @15_m1_297[@ri_311]) then
                  yield
                orfind @i_314 = @ri_313 <= N suchthat defined(@15_m1_279[@ri_313]) && (m3 = @15_m1_279[@ri_313]) then
                  yield
                orfind @i_316 = @ri_315 <= N suchthat defined(@15_m1_275[@ri_315], @i_527[@ri_315]) && (m3 = @15_m1_275[@ri_315]) then
                (
                  if (!_189 = @i_527[@i_316]) then   (* Should find a contradiction here *)
                  event endB(hostY, B, Na_486, Nb_254)
                )
              )

@15_m1_275[@ri_315] defined implies @i_332[@i_527[@ri_315]] defined
so @i_332[@i_527[@i_316]] defined.
The equality !_189 = @i_527[@i_316] implies that @i_332 defined, 
which is impossible at this point (@i_332 is defined in another 
branch of find).
SOLVED: cryptoverif now detects that.

WEB

PROTOCOL ../../dev/web/webperso/cryptoverif/kerberos/PublicKeyKerberos_keyuse_SK_client.cv  OK
Slower: old=31.800 new=50.583
PROTOCOL ../../dev/web/webperso/cryptoverif/kerberos/PublicKeyKerberos_OptSubKey_server.cv  OK
Slower: old=13.230 new=17.269

==> Slow!
Faster after improvement in simp_equal_terms to automate sako and kerberos
below.

NDTESTS

PROTOCOL examplesnd/test/needham-schroeder-pkcorr3BlockAuth-tryautomate  
RESULTS DIFFER! Expected:
All queries proved.
Actual:
RESULT Could not prove event inj:endB(x, y, na, nb) ==> inj:beginA(x, y, na, nb), event inj:endA(x, y, na, nb) ==> inj:beginB(x, y, na, nb), event endA(x, y, na, nb) ==> beginB(x, y, na, nb).

==> That's the same problem as for needham-schroeder-pkcorr3BlockAuth (but notice that it manages to prove event endB(x, y, na, nb) ==> beginA(x, y, na, nb) !)

PROTOCOL examplesnd/test/signedDH-ssh  
RESULTS DIFFER! Expected:
All queries proved.
Actual:
RESULT Could not prove secrecy of keyA.

==> SOLVED by removing useless keys.

PROTOCOL examplesnd/test/signedDH-ssh-onesession2  
RESULTS DIFFER! Expected:
RESULT Could not prove secrecy of keyA.
Actual:
All queries proved.

==> that's actually progress
Modified the expected result accordingly.

DONE 26/5/2015
- * automate the proof of sako-ov-sound.cv
simplif_add (dec(c1, keyone) <> bidToBit(bidval)) knowing
Substitutions:
(dec(c1, sk) = bidToBit(bidval))
(sk = keyone)
(m1 = bidToBit(bidval))
Facts:
Elsefind:

Adding (dec(c1, keyone) <> bidToBit(bidval))

Trying to apply the rewrite rule "x <> x -> false"
in Terms.apply_eq_reds leads to testing
"Terms.simp_equal_terms try_no_var dec(c1, keyone) bidToBit(bidval)"
where try_no_var = Facts.try_no_var (substitutions above).
However, Terms.simp_equal_terms and Facts.try_no_var 
apply substitutions only to variables, so not to dec(c1, keyone)
or bidToBit(bidval).
Hence the matching fails and the simplification is not
detected.

DONE 26/5/2015
  * finish the proof of
  ~/dev/web/webperso/cryptoverif/kerberos/PublicKeyKerberos_keyuse_SK_client.cv
  and other kerberos examples (test(b,Z(m1),Z(m2)) -> Z(m1) when Z(m1) = Z(m2))
  See examplesnd/kerberos/kerberos-conclude-simplified.cv
  for a small example that exhibits the problem.
  CryptoVerif tries to apply the rewrite rule test(b,x,x) -> x to
  test(b,Z(m1),Z(m2)). Trying to match the term test(b,Z(m1),Z(m2))
  with the pattern test(b,x,x) in Facts.match_term calls
  "Terms.simp_equal_terms try_no_var Z(m1) Z(m2)" where
  try_no_var = Facts.try_no_var (Z(m1) -> Z(m2)).
  However, Terms.simp_equal_terms and Facts.try_no_var 
  apply substitutions only to variables, so not to Z(m1).
  Hence the matching fails and the simplification is not
  detected.
==> Try to extend simp_equal_terms so that it uses rewrite
rules also on functions? Would that be too slow?

- transf_crypto: should I rather try to use try_no_var to get as soon
as possible the real values of variables, to avoid giving bad advice?
That would help in some cases of the Airbus case study.
(Sometimes, the variable contains the right value not because of an
assignment but because of a test. Advice is unable to replace it in
this case. In the Airbus case study, the protocol was reorganized so
that the value came from an assignment.)
DONE

NSSK Needham-Schroeder shared key: 
Show that N_b[i] = N_b[i']-1 has negligible probability.
Solution: when testing a collision M1 = M2, with M1 characterizing a
part of N and we want to show that M2 does not depend on N but fail,
distinguish the cases:
- indices of N equal in M1 and M2 -> leads to (eq indices) && M1 = M2
  Make sure that we transform M1 = M2 into a simpler term with equal
  indices, so that we avoid loops.
- indices of N different in M1 and M2 -> we should be able
  to show that M2 does not depend on N
DONE 6/7/2015

ABANDONED
- Improve the collection of true facts: when we make the intersection
of set of facts because variables may be defined at several places,
use the variables already known to be defined in order to eliminate
some possibilities.
That could be implemented by storing in nodes the list of variables
that may be defined at that node with the same replication indices
(actually possibly a different number of replication indices,
but prefixes of the same list).
Then eliminate nodes for which a variable known to be defined
is not in that list.
That should allow us to avoid SArenaming variables in some cases.
TRIED on July 14, 2015. DOES NOT WORK.
See srcnd/eliminate_non_compatible_nodes_in_add_facts.works_badly.diff
for a diff of that experiment.
In fact, if we could eliminate some node using this process,
it is likely that another variable is known to be defined
and has fewer possible definition nodes, so we recover the information
anyway.
REINTRODUCED on 31/7/2015: It allows proving some correspondences
without doing an SArename.

- extend distinction on the order in which variables are defined,
to be able to prove both cases using "elsefind" facts. (Currently, we
can only prove one case using an elsefind fact and the other case 
by dependency analysis.)
DONE 21/7/2015

- extend the proof of secrecy, to support
      if .. then out(c, s) else let secret = s
that is, some cells of s are secret, others are leaked.
(for forward secrecy)
DONE 27/7/2015

- * better display of failure of secrecy proof.
  DONE 28/7/2015
  * record the work done for one-session secrecy,
  and reuse it in case there is another query for
  secrecy/one-session secrecy of the same variable.
  DONE 28/7/2015

- I could strengthen Success.check_usage_... by allowing
let b' = M in p else p when M depends on b[l], but is not exactly
equal to b[l]. (Obviously, the usages of b' still need to be checked.)
DONE 29/7/2015

- I could extend the transformation "insert" by allowing references
to terms defined but not explicitly included in the "defined"
conditions of "find", similarly to what I do for "replace".
Then the conditions of "find" may need to be updated.
DONE 29/7/2015

- understand why sometimes I advise (SArename x) when
  x cannot be SArenamed (has a single def / occurs in queries)
  and avoid that (especially the case in which x has a single
  definition).
Example: examples/needham-schroeder-pkcorr3Block.cv
It really comes from global dependency analysis.
More precisely, from check_assign2.
This is really strange: we have a single definition of b,
by let pat = M in p else p', M does not depend on b0,
but still b is found in dvar_list, so b depends on b0!
b = Nb_197, b = @15_x_275 has several definitions
In fact, what happens is that at the point of global
dependency analysis, the variable really has several definitions.
But the dependency analysis advises several SArename instructions.
The first of the these instructions, with the associated
simplifications, remove assignments to variables that
appear in subsequent SArename advised instructions,
so these later SArename do not change anything...
29/7/2015: UNDERSTOOD, not changed.

- Regression after adding try_no_var in transf_crypto (11/05/2015):
PROTOCOL examplesnd/test/needham-schroeder-pkcorr3BlockAuth-tryautomate  
  RESULTS DIFFER! Expected:
  All queries proved.
  Actual:
  RESULT Could not prove event inj:endA(x, y, na, nb) ==> inj:beginB(x, y, na, nb), event endA(x, y, na, nb) ==> beginB(x, y, na, nb).
It would need "SArename @15_m2_307" as manual proof step,
as in examples/needham-schroeder-pkcorr3BlockAuth.cv
However, the goal of this file was to make a fully automatic proof...
(It is displayed as user advice by CryptoVerif, but not 
automatically applied. The problem may be solved by improving
the proof strategy so that the user advice is applied.
But it needs to be applied only as a last resort,
otherwise other examples will fail because it is applied
as the wrong place. That would simplify the manual
proof steps of examples/needham-schroeder-pk[corr]3BlockAuth.cv
as well)
FIXED 31/07/2015 (by using compatibility to avoid considering
some definitions of variables in the collection of true facts,
when proving correspondences)

- In the proof of correspondence assertions, when the event is
removed by an intersection, instead of advising SArename,
I could try to complete the proof by considering the two cases
separately to avoid the intersection.
DONE 31/07/2015, but it appears less powerful than SArename
(see authexamples/denning-sacco-corr3Block.cv for instance
--> that example fixed.)
Should I keep the advice anyway? Or make it stronger?
   * DONE remove is_useful
   * DONE to benefit from compatibility of nodes, use done_refs in addition
   to seen_refs in add_facts and add_def_vars
   * PARTLY DONE simplify further the case distinctions (see TO DO in facts.ml)
   The rest is likely not to bring much benefit in practice.
   * STILL TO DO improve case distinctions: when I assume that a variable
   is defined at a certain point, this implies that other variables
   are also defined at certain points and not others.
   * LEFT AS IT IS the runtime penalty does not seem that big.
   the case distinctions and the use of compatibility of nodes
   introduce a runtime penalty. Optimize? Allow not to use them?
   * DONE improve comments
   * DONE compare tests with 29/07/2015;
   DONE fix proof of 
   examplesnd/test/JoeKaiTsay-UMTSAKA_NONCEOnefiPRPcipher_CpaEncWufMac_fix
   OK check result of
   ../../dev/web/webperso/cryptoverif/kerberos/BasicKerberos_AS.cv ok
DONE 4/8/2015

improved merging of find branches
examplesnd/test/Avik-prf.CV: A more powerful merging of branches
of if/let/find when they execute the same code would be useful.
(Support renaming of variables used in arrays; this is ok in this
file because the taken branch is always the same, since it depends
on a variable set once and for all in the game.)
See examplesnd/test/Avik-luby-rackoff-corrected.CV for another example
of the same kind.
DONE 5/8/2015

- Display an explanation of why a cryptographic transformation
fails.
DONE 26/8/2015

- Modify compatibility tests
(CompatibleDefs2.check_compatible2_deflist,
CompatibleDefs.check_compatible_deflist) so that, instead of deriving
a contradiction when array indices are equal, they add a fact saying
the array indices are different. The contradiction may be later
derived by simplification.
DONE 28/7/2015 for CompatibleDefs2.check_compatible2_deflist
DONE 31/8/2015 for CompatibleDefs.check_compatible_deflist
* If this is implemented for CompatibleDefs.check_compatible_deflist, 
I could probably remove the call to
CompatibleDefs.check_compatible_deflist at each test.
DONE 31/8/2015
* Even when I consider the compatibility of two variables, I may use a
prefix of the indices instead of the full indices. The compatibility
checking needs to determine the right length of that prefix.
DONE 31/8/2015
* CompatibleDefs.check_compatible_deflist needs to compute the length of
the prefix instead of checking it. That may lead to a slower
implementation.
DONE 31/8/2015
* One possibility: 
Represent sets of program points using intervals of occurrences,
since by move_occ_term/process, these sets contain consecutive occurrences.
I record the information only when there is an incompatibility
(branches of if/let/find) between program points.
For variables and program points: a variable b[l] may be defined at
the current program point pp' with indices l' when there exists a
definition of b at program point pp such that pp with indices l
can be executed before pp' with indices l'.
For two variables: variables b[l] and b'[l'] can be defined simultaneously
when there exist a definition of b at program point pp and a definition
of b' at program point pp' such that pp with indices l can be executed
before or after pp' with indices l'.
DONE 31/8/2015

- In  examplesnd/arinc823/lemmaMAC_*.ocv, some
terms are equal to false, and simplify does not find that
automatically, I need to use replace. When terms
are equal to true, simplify works. Try to improve that.
The reason why it does not work is really stupid:
the script returns (m1=m2), but the manipulated term
is ((m1=m2)) with a one-component tuple around (m1=m2).
So ((m1=m2)) is of type bitstring and not bool, so
Facts.simplify_term does not apply simplify_term_rec,
which applies only to terms of type bool. Should I apply
simplify_term_rec to all subterms of type bool?
DONE 6/9/2015

- Bug: in transf_crypto.ml, when Settings.use_known_equalities_crypto
  = true, simplification may require the update of defined conditions
  of find.
FIXED 23/10/2015

- Allow more precise manual guidance of cryptographic transformations,
by specifying which terms should be transformed using which oracles.
In particular, for public-key encryption, allow to transform
some but not all occurrences of encryption. That should allow
a faster and simpler proof for protocols like Needham-Schroeder,
by transforming encryptions only in the honest session.
Also, be able to specify which random values in the equivalence
should be mapped to which random values in the game.
(In this case, I do not need to restart from a single random value
when computing the mapping.)
DONE 29/10/2015

- Remove assignments "let x = .. in" in conditions of find
DONE 29/07/2016

- Modify the formalization of IND-CCA2-INT-PTXT.
Provide IND-CCA2 and INT-PTXT as separate properties.
When both are given, it may be better to allow
applying either IND-CCA2 or INT-PTXT but not one after the
other, instead of applying IND-CCA2 after INT-PTXT.
=> In fact, when both are given, I allow applying 
one after the other in any order.
DONE 1/8/2016

Note: IND-CPA + INT-CTXT also works by grouping both
transformations into a single one.
See srcnd/ind_cpa_int_ctxt.cvl

- In find j s.t. defined(x[j]...) && cond then ... else let x = ... 
the elsefind fact "for all j, not (defined(x[j]...) && cond)"
is currently removed at the "let x = ...", because x may now
be defined even if it was not before.
I could do better: I could transform it into
"for all j, not (defined(x[j]...) && cond && i <> j)"
where i is the current replication index (so x[i] is the variable
defined by "let x = ...").
Indeed:
For i = j, i<>j is false, so defined(x[j]...) && cond && i <> j is
   false, so not (defined(x[j]...) && cond && i <> j) is true.
For i<>j, not (defined(x[j]...) && cond && i <> j) is equivalent to
   not (defined(x[j]...) && cond) so it is true because it was true
   before the definition of x[i].
DONE 20/9/2016

- Airbus examples:
    * Automate the replacements of MAC
I thought that using try_no_var to get the real values of variables
in transf_crypto would help for that, but it does not.
We have oracles mac(k,v) and mac(k,v) = mac(k,v') in the LHS
of the equivalence; in the game, we have x = mac(k,v),
x' = mac(k,v') by conditions of tests and we would like to transform
x = x', first into mac(k,v) = mac(k,v'), then using the
crypto transformation. However, since x = x' does not contain 
the name k to be discharged, it is considered OK without 
examining it in more detail. The crypto transformation fails
because it never uses the oracle mac(k,v) = mac(k,v')
which is marked "useful_change".
I managed to automate that replacement by adding the equation
forall k: mac_key, m1: bitstring, m2: bitstring;
       (MAC2(k, m1) = MAC2(k, m2)) = MAC2collision(k,m1,m2).
This equality allows simplification to automatically transform
x = y into MAC2collision(k,m1,m2) when x = MAC2(k,m1) and y = MAC2(k,m2).
That's good. It would be even better if it worked without such a
trick. Or should I systematically use this trick in the
specification of cryptographic primitives?
See the scripts examplesnd/arinc823/arinc*-auto.cv
    * How to complete the proof of
arinc823-secret-key.SECRECY.ENC_SUPPORTED.cv
without manual inspection of the final game?
Distinction on the order in which variables are defined,
but different from what CryptoVerif can already do!
See arinc823-secret-key.SECRECY.ENC_SUPPORTED-simplified2.cv
=> 20/9/2016 seems to work with the improved treatment of
elsefind facts
    * Revise the scripts to avoid using the option
set useKnownEqualitiesInCryptoTransform = false
=> OK in the scripts examplesnd/arinc823/arinc*-auto.cv

- Remove find when it always succeeds and the indices
are not used (except in the condition of find).
I thought I already did that, but it seems not,
see examplesnd/arinc823/lemmaMAC_SUFCMA_KDF_PRF.ocv
DONE 20/9/2016

- I could use Simplify1.convert_elsefind/add_elsefind more often
to add more facts inferred from elsefind facts (use them in
Facts.get_facts_at? or directly in Terms.build_def_process?
It cannot be done in the same pass as Terms.build_def_process
because we need to know the defined variables at each point,
and this is fully known only when Terms.build_def_process is finished.)
Similar remark for Simplify1.get_facts_of_elsefind_facts.
Similar remark as well for compatibility tests.
DONE 30/9/2016: 
* convert_elsefind/add_elsefind and compatibility tests
taken into account in Simplify1.improved_def_process.
It takes a bit of time and does not really help on the current
examples, so perhaps I should deactivate it by default.
* Simplify1.get_facts_of_elsefind_facts taken into account in 
the proof of correspondences (check_corresp.ml)

- Take into account elsefind facts to prove injective correspondences,
to prove inj:Recv3 ==> inj:Send3 in
TextSecure-v3-HonestOnly-OneMessage-AB-BA-3DH-antireplay.cv
Similar situation in 
dev/projects/2014ANRAirbus/arinc823publickey/computational/arinc823-public-key.AUTHENTICATION.ENC_SUPPORTED-v2.cv
Works for the small example:
dev/projects/2014ANRAirbus/arinc823publickey/computational/arinc823-public-key.AUTHENTICATION.ENC_SUPPORTED-v2-groundinit.cv

For
   dev/projects/2014ANRAirbus/arinc823publickey/computational/arinc823-public-key.AUTHENTICATION.ENC_SUPPORTED-v2.cv
it manages to prove the injective correspondence when I remove
duplicates from and/or combinations in Terms.make_and_list/make_or_list.
(CV knows sid_1 <> sid_2 and needs to prove a contradiction
with (sid_1 = sid_2) || (sid_1 = sid_2). It does not manage
to do that, but succeeds if (sid_1 = sid_2) || (sid_1 = sid_2)
is replaced with just (sid_1 = sid_2).)

However, that prevents CV from proving
event recv_msg(V, U, tU, sU, randV, policy_id, policy, enc, count,
   msg) ==> ((policy = get_policy(policy_id, msg))&&(send_msg(U, V,
   tU, sU, randV, policy_id, policy, enc, count, msg)||(policy =
   NONE))) !!!!
A simplification removes @i_2873[@i_2803] = !_619 from a condition
of find, which is probably correct, but prevents proving the
correspondence because CV needs this equality and does not manage 
to reprove it after it has been removed...

=> Problem solved by improving the collection of facts and 
using elsefind facts in the verification of correspondences.

Works for TextSecure
DONE 3/10/2016

- I think there is a bug in the simplification that removes
find when the indices are not used and the condition of find
always succeeds. It could remove useful defined conditions,
which always hold but are needed to preserve the syntactic
invariant that we verified that variables are defined
before using them.
FIXED 4/10/2016

- The update of defined conditions of find in
Facts.update_def_list_term
Facts.update_def_list_process
may not be entirely sufficient. For now, I raise an
internal error in case it does not work.
Possible improvements:
* Take into account known facts when testing equality
between binder references, to attribute defined references
to the right "find".
* One may need to add defined to "if" (thus changing
it into a find) in code like
   find j1 ...suchthat defined(x[j1]) then
   ....
   if j1 = j2 then
   ....x[j2]....
x[j2] guaranteed to be defined because x[j1] is defined
and j1 = j2, but I cannot add x[j2] to the defined condition
of the find, because at this point, I do not know yet that
x[j2] is defined. I know it only at the test j1 = j2.
(see also examplesnd/test/bug_defined_cond_simplify2.cv)

A similar phenomenon may happen with let with pattern matching,
when it is only by reasoning using the success of pattern matching
that one can infer that a certain variable is defined.
(see examplesnd/test/bug_defined_cond_simplify3.cv)

The best may be to add these supplementary defined conditions
that cannot be included in a find, just above the term that
uses the variable in question.
FIXED 7/10/2016

- Prove that several variables are *independent* secrets.
==> Useful for TLS.
DONE 2/11/2016, by allowing public_vars in secrecy queries.

* In the collection of true facts, I could also consider only
the definition points of variables that are compatible with the
current program point.
This also requires testing compatibility between program points.
DONE 3/11/2016

- Suppose that I collect the variables known to be defined at a certain
point and the facts that hold at a certain point o,
x[M] is defined as a result of a defined condition above o,
x[i] is defined in a block other than o, and above the definition
of x[i], there is a defined(y[N]) condition.
When y is defined in the same block as o, above o, I currently
consider that that block may be executed until o at index N{M/i}.
In fact, that block must be fully executed at index N{M/i},
and that index is different from the current index.
(The reason is that the block (1) that defines y[N{M/i}] must
be executed before the block (2) that defines x[M], which itself
must be executed before the current block (3) containing o.
Since block (2) is different from blocks (1) and (3),
block (1) is fully executed before block (2) which is also
fully executed before block (3).)
Hence the future variables of y[N{M/i}] are all defined,
and the associated future facts hold.
DONE 3/10/2016 but
* I could push it further, by inferring that indices must
be different as follows:
suppose I am at program point p with indices l0, I infer that a
variable b[l1] is defined in another block, and I infer from 
that, that b'[l2] is defined in the same block as a p, or a 
block that follows it. In that case, l0 <> l2, because the 
definition of b is executed before the block at program point p,
and the definition of b' is executed before the definition of b.
DONE 3/11/2016
==> Probably useful for TLS: avoid the useless id(.) function
in tls13-core-PSKandPSKDHE-NoCorruption-ResumptionSecretLeaked.cv
and tls13-core-PSKandPSKDHE-NoCorruption-TrafficSecretLeaked.cv.

- Have exactly the same syntax to enter proofs manually and in the
input file.
DONE 19/7/2017

- In Transf_expand, simplify on the fly during expansion,
   instead of simplifying then expanding.
   This allows to cut more branches: e.g.
   let (x,s) = if cond then (true,s) else (false,s) in
   let r = if x then t1 else t2 in...
   expands to
   if cond then
      let (x,s) = (true, s) in
      if x
      then let r = t1 in...
      else let r = t2 in...[can be cut since x = true]
   else
      let (x,s) = (false, s) in
      if x
      then let r = t1 in...[can be cut since x = false]
      else let r = t2 in...
   We need to have expanded the first "let" to be able
   to simplify the second one.
DONE July 2017

Explain the failure of the proof of correspondence properties.
Improve the debug info by giving occurrences.
DONE 26/10/2017

CV does not manage to prove the injective correspondence
recv_msgU ==> send_msgV in 
dev/projects/2014ANRAirbus/arinc823publickey/computational/arinc823-public-key.AUTHENTICATION.ENC_SUPPORTED-v2.cv
To prove it, CV should use elsefind facts, the problem is
that event recv_msgU occurs just before "let received_count_table_960",
so CV does not realize that received_count_table_960 is defined at the
other repl. index. Two possible fixes:
* swap the two instructions => requires a new swapping command,
which might be useful in some other cases
* use the future binders and facts DONE 30/10/2017
* use "set autoMove = false" => works. Use that as a work around until
one of the other ways is implemented.

- Simplification is very slow in implementation/ssh/ssh-secrecy-key.ocv
It worked ok in CryptoVerif 1.20 and started being slow already in
CryptoVerif 1.21.
   Solved by deactivating elsefindFactsInSimplify at the beginning of the
   proof, to speed up simplification after crypto rom(h).
   Reactivated later, because it is needed in the proof.
DONE 30/10/2017   

Support let (b, =b) = ... ?
ABANDONED. This would be a bad idea. 

Terms.def_vars_and_facts_from_term to exploit the information
from complex conditions of find.
DONE 23/3/2018

   1) Incompatible front-end:
   Two main goals:
   - Compabibility with ProVerif (cf proverif/future/projet_xVerif.txt)
   - Be able to parse intermediate games displayed by CryptoVerif.
      
* DONE(before) table/insert/get, macros "letfun f(...) = ...", 
* DONE allow insert/get in terms (but not in conditions of find)
  Useful for
   repos/ProtoTLS/cv/drafts/tls13-core-InitialHandshake-with-tables.cv
  I will need to extend ProVerif as well with that.
* DONE Generate fresh ids without using ! or @ in identifiers for games
      generated by CryptoVerif
* DONE Allow events in terms? I would say yes, for uniformity.
   (but not in conditions of find/get, obviously)
* DONE For channels, accept "c", the replication indices being implicit
      (for compatibility with ProVerif)
     and "c[i1...in]" where i1...in are the current replication
      indices (for reading intermediate games)
* DONE define -> def,
* rather NOT? Allow patterns as arguments of process macros and letfun??
* DONE Remove otheruses
* DONE Note: the lexer for user commands does not allow ! in identifiers.
That would be needed for replication indices. However, using
replication indices in commands may require other changes.
=> solved by not using ! for replication indices.

   a) For find, accept "find u <= n" and "find u = i <= n"
   DONE

   b) Revise queries:
   b.1) Like in ProVerif, allow grouping queries together.
   The groups are not significant for CryptoVerif: all queries are
   considered together. [Later, we will introduce a "focus" proof
   instruction, to focus on a subset of the current queries,
   and "undo focus" to go back at the point before "focus".
   The queries proved in the meantime are removed.]
   b.2) Use "public_vars ..." to specify public variables for
   correspondences (like for secrecy).
   b.3) Use "event(...)" for each event in a correspondence,
   not at the beginning of the whole correspondence.
   Use "inj-event(...)" instead of "inj:...".
   b.4) Use "query secret x [onesession]" instead of
   "query secret1 x".
   DONE
   DONE onesession -> cv_onesession. Ignore all options starting with pv_

   ABANDONED FOR NOW use "public_vars ..." as a query modifier, which modifies
   all queries of a group. That guarantees that all queries of a group
   have the same public_vars, which is useful for ProVerif.
   (Fix the converter accordingly)
   I am hesitating about this idea. Is it clearer to have the public
   variables for each query? The syntax for the public_vars modifier
   may not be so nice: query secret x; public_vars x1,...,xn.

   c) Parametric processes
   DONE

   CryptoVerif may accept processes that intuitively it should not accept,
   because variable references are not defined at the point they
   are used as arguments of parametric processes, but become defined
   when the argument itself is used.
   I should perhaps have a list of defined references in check_process
   itself, to display an error in this case.
   Question: should I accept a reference to x (with the current indices)
   when x is not in the environment (that is, in scope),
   without a condition "defined(x)" above?
   Currently, I accept that, and it may work, because x may become in
   scope after expansion of parametric processes.
   I think I should not accept it because it is counter-intuitive with
   parametric processes. This is solved by including in the list of
   defined references above only those in "defined" conditions, not
   those in scope. The defined references should not be transmitted
   through parametric processes.
   DONE
   
   c bis)  equation -> equation builtin
      forall ...; M -> equation forall ...; M
   DONE
   
   d) For variables with global references (secrecy & public variables
   in queries), allow them to be defined several times, but with the
   same type and in different branches of if/let/find.
change the treatment of variables defined multiple times: when they
are used in find/queries, do not rename them, but verify that they are
defined in different branches; otherwise, rename them to distinct variables.
I think this requires 3 passes:
      1) find which identifiers are used in find/queries
      2) generate binders for these identifiers (must be done at the
   definition point(s) to know their type); check that all definitions
   of the same binder have the same type and are in different branches
   of if/let/find.
      3) build the process
   In fact, I think 2 passes could be enough, by returning the sets
   of binders defined in each process, and merging these sets appropriately.
   DONE
   
Implementation: allowing several definitions of a variable
used globally, with the same type, in different branches of if/find/let/get
has an impact on variables written to/read from a file by a module
in the implementation: such a variable may be sometimes bound inside
a term, sometimes in a process.
FIXED: I display a warning in this case, to inform the user that
only the variable bound in a process will be written to a file.
That should be sufficient for modules that want to read the variable.

   e) allow referencing replication indices in the game
   [I think it's already done, but might be worth checking.
   One point that may be missing is to allow
   let x <= n = M in (let storing a replication index)
   Done now.]

   At this point, I should be able to parse games output by
   CryptoVerif.
   Seems to work up to the following caveats:
   - Occurrence numbers {...} must be deleted before parsing.
   - Constants cst_<type> are introduced by CryptoVerif. Their
   definition needs to be added.
   - Events may be introduced by Shoup's lemma. Their definition
   needs to be added.
   - When some queries are proved, the corresponding variables
   may be removed from the game. The proved queries need to be
   removed to avoid referencing unknown variables.   
   - Games with undefined variables are rejected. I could add an
   option to transform that error message into a warning (when
   it occurs in a "defined" condition). DONE.
      set allowUndefinedVar = true.

   DONE To allow parsing intermediate games using symbols local
   to macros, have a second set of macros that passes all
   symbols as arguments. (The macros *_r can be replaced by macros of
   this second set.) Note that if we change the set of macros during a
   proof, we may need to revise variable numbers, etc.

   DONE Find a way to avoid clashes between names in the script and
   names local to macros. The problem appears only for global
   declarations that are not defined in the script. Local variables
   are renamed. And correctly declared globals are reserved by
   recordid. So it would be enough to remove such global declarations
   coming from macros without appearing in arguments from the
   environment when the macro ends.
   The same problem also occurs for nested macros! (An identifier
   defined in an inner macro can be used in an outer macro without
   being passed as parameter.) And the solution above does not work
   with the current expansion of inner macros at the definition.
   Moreover, there is another problem: see
   examplesnd/test/bad_ren.cv
   => I need a full revision of macro expansion.

   DONE There is still a possibility of clash between names of variables
   in macros (in processes and letfun) and names of variables used
   in queries or in array references. See
   examplesnd/test/clash_macro_global_var*.cv
   I really need to fix this bug.

   DONE allow replication indices in arguments of letfun and tables.

   f) write a converter from the old front-end to the new one.
   Changes in the converter:
   DONE define -> def
   DONE compos -> data
   DONE decompos -> projection
   DONE equiv name(id) -> equiv(name(id)) / equiv name -> equiv(name)
   DONE equation -> equation builtin
      forall ...; M -> equation forall ...; M   
   DONE syntax of equiv, collision uses the oracle front-end syntax
   even in the channels front-end
   DONE syntax of queries; generate the correct "public_vars ..."
   for correspondences.
   DONE use the full process after expansion of process macros,
   to avoid problems with parametric processes.

      DONE Queries are hard to display from parsed versions (distinguish
      events from predicates?). If queries were to occur inside a
      macro, it might happen that they should be converted in a
      different way for different macro expansions depending on
      way a symbol is an event or a function. =>
      display queries from the version after syntax;
      prevent queries inside macros.
      DONE (including case @dummy_channel) I should output parsed versions of
      equiv/collision to be able to do it inside macros.

      DONE Avoid generating names with @, because they will not be accepted
      as input.
      DONE Have an option to convert a library.

   display fixes:
     ABANDONED - display_(p)procasterm: indent and go to the next line
     like a process (both in src and converter)
     DONE - display_process: add some parentheses around terms
     (both in src and converter)
     DONE display_procasterm: put parentheses like a process (in src; already
     done in converter)
     DONE - may_have_else*: return true when the process could have an
     else branch *and does not have one*
     
     DONE remove keyword "end", use only "yield". Reserve "end"
     for the construct "begin P end; P'" that we plan to introduce later.

     DONE reduce the numbers used for variables

      DONE the display of | (in the converter and probably also in
      cryptoverif itself) is not coherent with the priorities of the
      parser. See examples-1.28-converted/nd/test/bugeq6.cv

      DONE examplesnd/test/channels_with_explicit_indices.cv
      CryptoVerif rejects this file, perhaps because the indices
      are passed as arguments to the process. It should accept it.
      (CV was creating a "let"; now it is using the replication index
      directly)

      DONE consider the variables defined in equivalences as local
      (by resetting the counters to their state before the equivalence)
      both in CV and in the converter. 

      DONE Variables are also created when expanding macros,
      that uses some names, and I can now reuse them in the process.
      I consider the identifiers introduced during renaming of
      equiv, equation, collision, and letfun statements as local
      (except the function defined by letfun itself), by storing
      the renaming state at the beginning of these statements and
      restoring it at the end. Renaming state = the table of indices
      in terms.ml plus the renaming table in syntax.ml.

      NOTE Changes in occurrence numbers may be due to reorganizations
      of parallel compositions.

      DONE convert all existing examples
      I also need to update proof indications.
      The automatic converter does not convert examples with errors.
      I should convert them by hand.
      rename all files in nd/otest into .ocv
      update the expected result for all scripts, when it is
      "Could not prove". When it is "All queries proved" or an error,
      check that it is not changed.

   g) Revise the crypto library
   g.1) DONE do not use a key generation function for shared key primitives
   g.2) DONE add probabilistic MACs, deterministic signatures (use "letfun" 
   for probabilistic primitives)
   g.3) DONE Have a library of primitives with manual crypto transformations
that can leave some terms unchanged (e.g. verification of signature,
public-key encryption), even if the default behavior in automatic
game transformations would be modify them.
   g.4) DONE I could add square_CDH, square_DDH, square_GDH, and
square_GDH_prime_order in the library of crypto primitives.
(Check probabilities!)
When the group has prime order, CDH is equivalent to square_CDH
and GDH is equivalent to square_GDH, but CryptoVerif can do
more transformations with the square variant.

      DONE For the "partial" transformations for shared-key primitives,
      the probability is not optimal, because we consider the
      total number of calls to enc/dec/mac, even those that are not
      transformed. To improve, I would need one more argument to
      Penc/Pmac, representing the number of calls not transformed.

      DONE update default.ocvl
      
      DONE update documentation.

      ABANDONED Could I merge the equivalences suf_cma_corrupt and
      suf_cma_corrupt_partial by giving higher priority to
      the oracles that make a change? (So the application without
      explicit indication of oracles change all occurrences as
      before.) => Not possible for various reasons:
      - the MAC partial equivalences do not rename function symbols.
        It is helpful to have another equivalence for corruption
        that renames them, to avoid applying the MAC property again.
      - the signature equivalences with corruption insist in
        transforming all occurrences of check. It may be helpful to
        have that. 
      DONE add "corrupt" oracles to INT-PTXT partial transformations.
      ABANDONED Modify GDH to allow m -> exp(g, mult(m,a)) as an oracle,
      left unchanged, without corrupting a.
      (It can be computed as exp(exp(g,a),m) and exp(g,a) is public.)
      I tried but it needs too much advice (see examplesnd/notest/wireguard-modified-GDH.cv)
      ABANDONED ROM...all_args and ICM...all_args with variables and channel of
      oracles as arguments. 
         Was used by B. Lipp for wireguard, but in fact he also adds the
         random r created by the hash oracle, and that's the only
         variable really useful. Adding random variables created by
         equivalences to all macros _all_args would be too heavy, I think.
         

   h) DONE Revise examples manually to use the new crypto library
   Use authenticated encryption as the symmetric encryption scheme
   for DY-like protocols (not encrypt-then-MAC or others).

      
   h-bis) DONE Remove "compos" and "decompos" to keep only
   "data" and "projection"?
   
   i) DONE Update scripts test, distrib, ... with all examples
      At this point, I could make a release

   in ProVerif (branch compat_cryptoverif)
   - DONE Allow get, insert, event in terms (by expansion).
   - DONE Use a <-R T as a synonym of new a: T,
      x [:T] <- M as a synonym of let x[:T] = M in,
      foreach i <= N do as a synonym of ! i <= N
     0 and yield are synonym, that's already done.
   - DONE allow (and ignore) CV implementation annotations in PV
   - DONE display the version number in help message
   - DONE allow conjunctions of events before ==>
      [New keywords: implementation, foreach, do, public_vars, secret]
   - query secret <variable> public_vars ... [options]
   public_vars x1, ..., xn can be encoded by adding an output
   of xi on a public channel just after the definition of xi for
   i=1,...,n.
      DONE P1) For syntactic secrecy:
   Could be encoded as follows: add an event x_contains(x) just after
   the definition of x, and use the query x_contains(v) && attacker(v)
   ==> false.
      DONE P2) For indistinguishability from random: add 
      new rand: Tx; out(pub, choice[x,rand])
      just after the definition of x.
      (It needs to be separated from all other queries.)
      ABANDONED P3) For one-session indistinguishability from random: add
      insert Tblx(x)
      just after the definition of x and add a process
      get Tblx(x) in new rand: Tx; out(pub, choice[x,rand])
      in parallel with the whole process. (Tblx is a new table.)
      I would probably get a false attack as soon as I have two
      different values of x!
      Other idea: add out(pub, choice[x,h(x)])
      just after the definition of x, where h is a fresh function
      symbol without equations. h(x) is indistinguishable from
      a random value, independent when x changes. That tolerates
      replays of the same x, but not situations in which several
      values of x are related in a different way, but still each
      independent of random. 
      If I do not have a better idea, I should just forget about
      one-session indistinguishability from random.
   - allow "public_vars ..." for correspondences
   ProVerif can stop or automatically separate the queries when the
   "public_var ..." qualifiers of several queries in a group are
   incompatible (that is, different).
      DONE reset occurrences either during encoding of the process
   or just after (using a function that just resets occurrences
   without creating variables)
      DONE how are variables arguments of letfun, defined in letfun,
      arguments of processes treated? Can they be used in
      "query secret" and in "public_vars"? what does CryptoVerif?
      Do the same in ProVerif. I think there is at least one problem:
      variables defined as arguments of processes may disappear in the
      final process and thus be ignored by "query secret" and in
      "public_vars".
      Looking at the source, CryptoVerif ignores all variables of
      letfun, arguments and others. It takes into account the
      arguments of output processes, but yields an error in case
      an argument of an input process is referenced in a query.
      Would it be better to allow referencing variables of letfun
      in find and queries in CV? => Yes, now done.
      In ProVerif, the arguments of letfun are directly replaced
      with their values during expansion, so they disappear.
      The variables/names bound inside letfun remain and can be
      referenced in queries.
      The arguments of processes are sometimes kept as "let",
      sometimes directly substituted, so they may or not be used
      in queries... => I must change that.
      Now, ProVerif adds a let for arguments of processes when
      they are used in queries. It writes an error message when
      variables defined in terms are referenced in queries (because
      the expansion of terms may change when they are defined).
      DONE document new queries
      DONE style emacs .pcv
DONE in CryptoVerif 2.00

The application of collision statements does not seem to fully
exploit the commutativity of mult.
In examples/tls13/tls13-core-InitialHandshake-1RTTonly.cv with 
collision x <-R Z; y <-R Z;
	  return(exp(g,x) = exp(g,y)) <=(1/|Z|)=> return(false).
collision x <-R Z; y <-R Z;
	  return(exp'(g,x) = exp'(g,y)) <=(1/|Z|)=> return(false).
and the GDH assumption of default-DHinprogress.cvl (not prime order),
collision x <-R Z; y <-R Z; forall X: G;
	  return(exp'(X, x) = exp'(g, mult(y,x))) <=(0)=> return(X = exp'(g,y)).
applies at a point where
collision x <-R Z; y <-R Z; forall X: G;
	  return(exp'(X, x) = exp'(g, mult(x,y))) <=(0)=> return(X = exp'(g,y)).
does not!
(Compare the game after the GDH transformation with these two collisions.)
CANNOT REPRODUCE

Check that the dependency analysis (FindCompos) does not use collision
statements with random arguments to show that a term characterizes these
random arguments.
OK: inside FindCompos, I use apply_eq_statements_at_root which applies
only statements, not collisions, to simplify terms in find_compos_bin.

document set useKnownEqualitiesWithFunctionsInMatching
DONE

For curve25519, let q be the order of the base point g.
let Z be the integers multiple of 8 modulo 8q.
mult(x,y) = x.y mod 8q (remains multiple of 8)
exp(a,y) = point a multiplied by y
the choice of a secret key is non uniform in Z: choose among
2^254 + 8n (n \in [0, 2^251-1]) that is 2^251 elements.

Then we have injectivity:
(exp(g,x) = exp(g,y)) = (x = y).

mult(x,y) = mult(x',y) may imply x = x'.

However, it is not true that exp(X, x) = exp(g, mult(x,y)) with random x,y
implies X = exp(g,y), because one may also have
X = exp(g,y).(element of small order).
CV infers that we cannot have  exp(X, x) = exp(g, mult(x,y))
when X does not depend on y, from injectivity properties of exp(g,.)
and mult(x,.) because exp(g, mult(x,y)) then characterizes y.

gy_3 defined => else branch of 
            find j' = j'_1 <= N1 suchthat defined(cr_1[j'_1], gx[j'_1]) && (sgx = gx[j'_1]) then
in the server

tls13core ... 1RTT-only example
if gy_3[j] defined:
- if gx[i] defined before sgx[j], then cr_1[i] defined before sgx[j], so
before the "find j' = j'_1 <= N1 suchthat defined(cr_1[j'_1], gx[j'_1]) && (sgx = gx[j'_1]) then" with repl index j.
Else branch taken => sgx[j] <> gx[i].
- if gx[i] defined after sgx[j], x_3[i] also defined after sgx[j].
gx[i] = exp'(G, x_3[i])
sgx[j] does not depend on x_3[i].
sgx[j] = gx[i] impossible by collision
(exp'(G,x) = Y) <=()=> false if Y indep of x.

   CV cannot exploit
find j_4 = j <= Nsend suchthat defined(sephSecAB1[j]) && (pow8(sephPubAB_1) = pow8(sephPubAB1[j])) && (pow8(x_pubB_1) = pow8(pubA)) then

else
   new r_38...

where sephPubAB1[j] = G8toG(gexpdiv8(g8, sephSecAB1[j]))
to show that r_38 is defined, not((pow8(sephPubAB_1) = pow8(sephPubAB1[j])) && (pow8(x_pubB_1) = pow8(pubA)))
assume sephPubAB1[j] defined after r_38, sephPubAB_1.
pow8(sephPubAB_1) indep of sephSecAB1[j]
pow8(sephPubAB1[j])) characterizes sephSecAB1[j]
=> low proba of equality.
But when adding the facts in get_fact_of_elsefind_fact
pow8(sephPubAB_1) = pow8(sephPubAB1[j]) is added first
and CV does not retest the collision between these terms
when it adds sephPubAB1[j] = G8toG(gexpdiv8(g8, sephSecAB1[j])).

workaround: remove_assign sephPubAB1[j].
or add t' last ?
   DONE (omitted in CHANGES)

   Update the manual and default.ocvl with the changes made
   in default-DHinprogress.cvl to allow "nonuniform" types.
   ("bounded" is required to express the runtime of functions without
   mentioning the length of the value in question; "nonuniform" can be
   used when we just want to choose random numbers.)
   "bounded, nonuniform" is also allowed, to have a non-uniform
   distribution on a bounded type!
DONE

   Revision of DH regarding prime order
   Check probability formulas.

   common_DH_proba => DH_proba_collision
   common_DH_prime_order => DH_good_group
   common_DH_rand_group_exp => DH_dist_random_group_element_vs_exponent
   common_DH_curve25519 => less specific name (also for 448, etc), comments

   TextSecure: revise proof.
   probably needs GDH with equality pow8(..) = pow8(..)
   
Document new DH macros.
Update ProVerif crypto library with new DH definitions
DONE 23/08/2018

- ProVerif cannot reconstruct the attack against injectivity
  in examples/cryptoverif/denning-sacco-corr.pcv
   Solved by V. Cheval
   
Macros ..._RSR require the exponents to be chosen uniformly in Z/qZ
but DH_good_group chooses them uniformly in (Z/qZ)*...
FIXED by adding 1/|Z| in ..._RSR so that exponents can also be
chosen in (Z/qZ)^*.

in remove_assign, when a variable has several definitions that
all use the same term, I could do as if there is only one definition.
DONE 27/9/2018

The improvements to ROM (H(..) = .. and H(..) = H(..)) could
also apply to PRFs.
We could also have PRFs with several arguments.
DONE
   We could add ROMs/PRFs with several results, returning a tuple of random
values (though splitting a single random result works ok).
ABANDONED

- have a way to designate occurrences such as
    - at "let x in[here]" (after the let in)
    - at "[here]let x" (before the let)
    - at "let x else[here]" (in the else branch of the let)
  and similar for find/new/oracle def/...
      DONE (in a slightly different way)

The occurrence designation "after" could work even if there is a line
without occurrence before the next line with an occurrence, to allow
    find ...
    (
{DESIRED OCC}
DONE 12/10/2018

   - Both in ProVerif and in CryptoVerif:
      remove the restriction that injective events are in different
      branches of if/find/let/get.
      DONE in ProVerif by V. Cheval.
      DONE in CryptoVerif 20/10/2018
      
examples/encryptBR93-1: 
        Automate (see new definition of onewayness in examplesnd/bug).
DONE 3/11/2018 by adding priority [2] for pkgen(r) in ow(f).

Improvements in TLS models (similar to Wireguard):
- define option return types
- use let concat(...) = ... for splitting random oracle results
DONE 6/12/2018

   I can use further simplifications for EventAbort: when I am
   sure that an EventAbort will be reached in the current block,
   I can remove the instructions before the EventAbort.
   Examples:
      let x = M in EventAbort e -> EventAbort e
      let pat = M in EventAbort e else EventAbort e -> EventAbort e
      new a; EventAbort e -> EventAbort e
      if M then EventAbort e else EventAbort e -> EventAbort e
      find ... then EventAbort e else EventAbort e -> EventAbort e.
   The simplification for "if" is already implemented (merging of 
   branches). The others may not be. In particular, the
   simplifications for let, new, find are valid even if the
   newly defined variable(s) have array accesses.
DONE 7/12/2018

   5/ I should also be able to tell CryptoVerif to focus on the
   proof of some of the properties, prove them, and then go back
   in order to prove other properties.
   That would allow a stronger use of item 4/ above, by focusing
   on some "required steps" only (possibly one).
   DONE
   notes:
   - we cannot focus on an equivalence query.
   This is not super useful, since anyway, we can prove equivalences
   only last, when all events are removed. Furthermore, 
   if we allowed proving equivalences with events in the middle,
   focusing on the equivalence should not remove the events,
   so it would not simplify the game anyway.
   - DONE right now, if I focus on a query whose proof depends on a
   Shoup event e not proved yet, I may be able to prove the query,
   but it will be forgotten when I do "undo focus". I should remember
   the partial proof up to the point at which the event e was introduced.
   (In doing that, remember that the proof of an event may depend
   itself on other events...)
DONE 28/1/2019

instruct.ml, command CFocus:
Syntax.check_query may stop in case of error by calling
input_error. That's not suitable in interactive mode,
it should raise Error(..,..) instead of calling input_error.
FIXED 30/7/2019

What is the impact of weak group assumptions
(e.g. curve25519/curve448) on PRF-ODH?
Reprove PRF-ODH from ROM and CDH/GDH plus minimal assumptions on
the group. Check that curve25519/curve448 satisfy these assumptions.
DONE ../8/2019

   => Is it really correct to apply simplification several times
   in "success simplify", always using the information collected
   by success, even if a simplification already occurred in between?
FIXED 6/8/2019: use the collected information only in the first
iteration.

      PRF-ODH: document, probability formulas + comments
DONE ../8/2019
      
   Use an EventAbort to represent that the adversary loses
   when it takes a branch that does not execute the "required step",
   that is, the end event when I prove a correspondence (easier to do
   when each correspondence has a single end event),
   the assignment to the variable when I prove secrecy.
   Hence, there are two kinds of EventAbort:
      - those in which the adversary wins when it is reached
        (already used in cryptoverif)
      - those in which the adversary loses when it is reached.
DONE ../8/2019

   I should add a transformation that simplifies the game
   as much as possible taking into account that the adversary
   loses when the "required step" (see definition above) is not
   reached. Insert EventAbort in branches that do not reach it,
   but not only: use facts inferred at the "required step" to infer
   contradictions anywhere in the game and insert EventAbort
   accordingly.
   Example: at the "required step", I can prove that M is true.
   If I have a test "if M then P else Q" somewhere (even in another
   process in parallel), I can replace it with 
   "if M then P else EventAbort lost".
   In principle, this transformation could be applied even when 
   the tested session is not guessed (in this case, I can insert
   EventAbort only when the "required step" cannot be reached in
   *any* session). It is much more powerful when it knows that
   there is a single tested session.
DONE ../8/2019

            Collection of facts in "success simplify":
   => Use elsefind facts for "event e ==> false" as I already do
   for "event_abort e ==> ..."?
DONE 6/8/2019

When I look for an occurrence, I could exploit the ordering of
occurrences and the field max_occ to avoid traversing the whole
game.
DONE 7/8/2019

Allow insert find[unique], provided CryptoVerif manages to
prove that the find is indeed unique.
DONE 8/8/2019

Use simp_facts in FindCompos.is_indep (as in Facts.is_indep)
DONE 23/8/2019

David: we could make sure that strings are not mutated in implementations
generated by CryptoVerif by defining an abstract type imm_string 
(immutable string), whose implementation is string, and defining
all functions that need to access the internals of strings inside the
same module. This has no cost in terms of performance.
DONE: the type string is now immutable in OCaml, and our code has
been revised to exploit that.

========== Notes on the change in FindCompos:

Improve FindCompos to exploit collisions (with non-zero probability)
in order to prove injectivity.
Currently, find_compos_bin works as follows:
  if M = X, X is independent of x, and M determines x, then 
  we bound the probability that M = X. "M determines x" 
  is proved by building M' obtained from M by replacing all variables
  that depend on x with fresh variables. In particular, x is
  replaced by x'. We prove that M = M' implies x = x', using
  only equations (no collision statements).
It would be better to work as follows:
  if M = X and X is independent of x, then there exists a term M',
  obtained from M by replacing all variables that depend on x with 
  fresh variables, such that M' = X and M' is independent of x.
  Then the probability that M = X is bounded by the probability that
  M = M'. The latter probability can be bounded using both
  equations and collision statements.
Note: the form chosen for M' is good when using equations/collisions
that show injectivity, e.g. (f(y) = f(z)) = (y = z), but in general
other forms of M' may perhaps be better? It still seems difficult to consider
other forms of M'.
The better definition of find_compos_bin would allow CV to infer
the collisions
collision y <-R Z; forall X: subG;
	  return(pow_k(subGtoG(exp_div_k(g_k, y))) = X) <=(2*Pcoll1rand(Z))=> return(false)
	  if X independent-of y.
+ the same with exp_div_k' instead of exp_div_k
+ the same with subGtoG instead of pow_k(subGtoG
in DH_X25519, DH_X448, DH_single_coord_ladder.


Difficulty: find_compos is used for computing some dependency information,
storing that a variable characterizes another.
If I change the interface of find_compos, I need to adapt that information as well.

**** src/simplify1.ml:1068:	match FindCompos.find_compos check (b, (None, defl_before)) (b,(FindCompos.Decompos, b.btype)) t1' with

	let check (b, (st, _)) l =
          if (!Settings.debug_elsefind_facts) then
            begin
              print_string "check: b="; Display.display_binder b; 
	      print_string ", l=";Display.display_list Display.display_term l;
	      print_string ", l_after'=";Display.display_list Display.display_term l_after';
	      print_newline ()
            end;
	  if List.for_all2 Terms.equal_terms l l_after' then
	    Some (st, FindCompos.CharacType b.btype)
	  else
	    None
	in
	match FindCompos.find_compos check (b, (None, defl_before)) (b,(FindCompos.Decompos, b.btype)) t1' with
	  Some(_, FindCompos.CharacType charac_type, t1'') -> 
	    begin
	    try 
              if (!Settings.debug_elsefind_facts) then
                begin
                  print_string "FindCompos ok";print_newline ()
                end;
	      let t2' = FindCompos.is_indep (b, (None, defl_before)) t2 in
	      (* add probability, if small enough. returns true if proba small enough, false otherwise *)
	      add_term_collisions (cur_array, true_facts, order_assumptions, Terms.make_true()) t1'' t2' b (Some l_after') [charac_type]
	    with Not_found -> false
	    end
	| Some _ -> Parsing_helper.internal_error "CharacTypeOfVar should not be used in DepAnal2"
	| None -> false


**** src/simplify1.ml:1832:	match FindCompos.find_compos check (b,FindCompos.init_elem) (b, (FindCompos.Decompos, b.btype)) t1_simp_ind with

	let t1_simp_ind = FindCompos.remove_array_index t1 in
	let check (b, (st, _)) tl =
	  if List.for_all2 Terms.equal_terms tl l_simp_ind then
	    Some (st, FindCompos.CharacType b.btype) 
	  else 
	    None
	in
	match FindCompos.find_compos check (b,FindCompos.init_elem) (b, (FindCompos.Decompos, b.btype)) t1_simp_ind with
	  Some(_, FindCompos.CharacType charac_type, t1') -> 
	    begin
	      try 
		let collect_bargs = ref [] in
		let collect_bargs_sc = ref [] in
		let (t2', t2_eq) = Facts.is_indep simp_facts (b,l,FindCompos.init_elem,collect_bargs,collect_bargs_sc) t2 in
		let side_condition = 
		  Terms.make_and_list (List.map (fun l' ->
		    Terms.make_or_list (List.map2 Terms.make_diff l l')
		      ) (!collect_bargs_sc))
		in
	        (* add probability; returns true if small enough to eliminate collisions, false otherwise. *)
		if add_term_collisions (cur_array, true_facts_from_simp_facts simp_facts, [], side_condition) t1' t2' b (Some l) [charac_type] then
		  Some (Terms.make_or_list (List.map (fun l' ->   
		    let t2'' = Terms.replace l' l t2_eq in
		      Terms.make_and (Terms.make_and_list (List.map2 Terms.make_equal l l')) (Terms.make_equal t1 t2'')
		      ) (!collect_bargs)))
		else
		  None
	      with Not_found -> 
		None
	    end
       | _ -> None

**** src/transf_globaldepanal.ml:275:          match FindCompos.find_compos check ((!main_var), (Some (!dvar_list), [])) b_st t0 with

(* [find_compos_list t] returns [Some(st,charac_type,t',l_opt')]
   when [t] characterizes a part of [b0] of type determined by [charac_type]
   (i.e. only one value of that part of [b0] can yield a certain value of [t];
   [st] is 
        - [Compos] when [t] is obtained from [b0] by first applying
        poly-injective functions (functions marked [data]), then
        functions that extract a part of their argument 
        (functions marked [uniform]).
        - [Decompos] when [t] is obtained from [b0] by applying functions
        that extract a part of their argument (functions marked [uniform])
   [t'] is a modified version of the term [t] in which the parts not
   useful to show that [t] characterizes a part of [b0] are replaced with
   fresh variables.
   [l_opt'] is [Some l] when [t] characterizes a part of the cell [b0[l]]
           and [None] when [t] characterizes a part of some unknown cell of [b0]. *)

let rec find_compos_rec t0 t =
  match t.t_desc with
    Var(b,l) when not (List.exists depends l) ->
      begin
        try 
          let (_,(_,(_,charac_args_opt,_))) as b_st = (b, List.assq b (!dvar_list)) in
          let check (b, (st, _)) tl =
            if Terms.equal_term_lists l tl then
              Some (st, CharacTypeOfVar b)
            else
              None
          in
          match FindCompos.find_compos check ((!main_var), (Some (!dvar_list), [])) b_st t0 with
	    Some(st,charac_type,t') -> 
	      let l_opt' = 
		match !charac_args_opt with
		  None -> None
		| Some b0_ind ->
		    (* b[args_at_creation] characterizes b0[b0_ind] *)
                    let l' = List.map (Terms.subst b.args_at_creation l) b0_ind (* b0_ind{l/b.args_at_creation} *) in
		    (* t0 characterizes b[l], so it characterizes b0[l'] *)
		    Some l'
	      in
	      Some(st,charac_type,t',l_opt')
	  | None -> None
	with Not_found ->
	  None
      end
  | FunApp(f,l) ->
      Terms.find_some (find_compos_rec t0) l
  | _ -> None

let find_compos_list t = find_compos_rec t t

Typical usage:

        match find_compos_list t1 with
	  Some(_, charac_type,t1',_) ->
	    if depends t2 then
	      BothDepB
	    else 
	      begin
                (* add probability *)
		add_collisions_for_current_check_dependency (cur_array, true_facts, fact_info) (t1', t2, charac_type);
		local_changed := true;
		if (f.f_cat == Diff) then OnlyThen else OnlyElse
	      end
	| None -> ...

**** src/transf_globaldepanal.ml:365:          match FindCompos.find_compos check ((!main_var), (Some (!dvar_list), [])) b_st t1 with

          let (_,(st,(_,charac_args_opt,_))) as b_st = (b, List.assq b (!dvar_list)) in
	  if st = Any then
	    (* [b] depends on [b0] but does not characterize it *)
	    raise Depends;
          let check (b, (st, _)) tl =
            if Terms.equal_term_lists l tl then
              Some (st, CharacTypeOfVar b)
            else
              None
          in
          match FindCompos.find_compos check ((!main_var), (Some (!dvar_list), [])) b_st t1 with
            Some(_, charac_type, t1') -> 
	      begin
		match !charac_args_opt with
		  Some b0_ind ->
		    (* b[args_at_creation] characterizes b0[b0_ind] *)
                    let l' = List.map (Terms.subst b.args_at_creation l) b0_ind (* b0_ind{l/b.args_at_creation} *) in
		    (* t1 characterizes b[l], so it characterizes b0[l'] *)
		    let collect_bargs = ref [] in
		    get_dep_indices collect_bargs t2;
		    if List.exists (List.for_all2 Terms.equal_terms l') (!collect_bargs) then
		      (* If t2 depends on b0[l'], we cannot eliminate collisions *)
	              raise Depends;
		    let side_condition = 
		      Terms.make_and_list (List.map (fun l'' ->
			Terms.make_or_list (List.map2 Terms.make_diff l' l'')
			  ) (!collect_bargs))
		    in
	            (* add probability; returns true if small enough to eliminate collisions, false otherwise. *)
		    if add_collisions_for_current_check_dependency2 cur_array true_facts side_condition (t1',t2,charac_type) (Some l') then
		      let res = 
			Terms.make_or_list (List.map (fun l'' ->   
			let t2'' = Terms.replace l'' l' t2 in
			Terms.make_and (Terms.make_and_list (List.map2 Terms.make_equal l' l'')) (Terms.make_equal t1 t2'')
			  ) (!collect_bargs))
		      in
		      (*print_string "Simplified ";
		      Display.display_term t1;
		      print_string " = ";
		      Display.display_term t2;
		      print_string " into ";
		      Display.display_term res;
		      print_newline();*)
		      Some res
		    else
		      None
		| None -> 
		    (* b[args_at_creation] characterizes b0 for some unknown indices *)
		    let collect_bargs = ref [] in
		    get_dep_indices collect_bargs t2;
                    if !collect_bargs != [] then
                      (* if [t2] depends on [b0], the dependency analysis fails to
			 eliminate the required collisions *)
		      None
	            (* add probability; returns true if small enough to eliminate collisions, false otherwise. *)
		    else if add_collisions_for_current_check_dependency2 cur_array true_facts (Terms.make_true()) (t1',t2,charac_type) None then
		      begin
		      (*print_string "Simplified ";
		      Display.display_term t1;
		      print_string " = ";
		      Display.display_term t2;
		      print_string " into false\n";*)
		      Some (Terms.make_false())
		      end
		    else
		      None
	      end
          | _ -> None


src/transf_simplify.ml:150:  match FindCompos.find_compos_list check var_depinfo seen_list' t with
=> This is the only call to FindCompos.find_compos_list.
Move it out of the FindCompos module and define it in transf_simplify.ml?

let check (b, (st, (bct, _))) l =
  if Terms.is_args_at_creation b l then
    Some (st, CharacType bct)
  else
    None

let find_compos_list ((b, (dep, nodep)) as var_depinfo) t =
  let seen_list' = match dep with
    Some seen_list -> seen_list
  | None -> [(b,(Decompos, (b.btype, Terms.term_from_binder b)))]
  in
  match FindCompos.find_compos_list check var_depinfo seen_list' t with
    Some(st, CharacType charac_type, t', b', (_,assign)) -> Some(st, charac_type, t', b', assign)
  | Some _ -> Parsing_helper.internal_error "CharacTypeOfVar should not be used in DepAnal2"
  | None -> None

(* checkassign1 is called when the assigned term depends on b with status st
   Raises Else when only the else branch of the let may be taken *)
let rec check_assign1 cur_array true_facts ((t1, t2, b, charac_type) as proba_info) bdep_info st pat =
  match pat with
    PatVar _ -> ()
  | PatTuple(f,l) ->
      let st' = if st != Decompos then Any else st in
      List.iter (check_assign1 cur_array true_facts proba_info bdep_info st') l
  | PatEqual t ->
      if (depends bdep_info t) || 
        (not (Proba.is_large_term t)) || (st == Any) then
	()
      else
	begin
	  (* add probability *)
	  if add_term_collisions (cur_array, true_facts_from_simp_facts true_facts, [], Terms.make_true()) 
	      t1 t2 b (Some (List.map Terms.term_from_repl_index b.args_at_creation)) [charac_type] then
	    raise Else
	end

(* check_assign2 is called when the assigned term does not depend on b
   Return None when both branches may be taken and
          Some(charac_type, t') when only the else branch of the let
          may be taken. t' is the term with which the collision is
          eliminated and charac_type is the type of the part of t'
          characterized by the value of t' *)
let rec check_assign2 bdepinfo = function
    PatVar _ ->
      None
  | PatTuple(f,l) ->
      begin
        match check_assign2_list bdepinfo l with
	  None -> None
	| Some(charac_type, l') ->
	    Some(charac_type, Terms.build_term_type (snd f.f_type) (FunApp(f,l')))
      end
  | PatEqual t ->
      match find_compos_list bdepinfo t with
	Some (status, charac_type, t', b2, b2fromb) when Proba.is_large_term t ->
	  Some (charac_type, subst b2 b2fromb t')
      |	_ ->
	  None

and check_assign2_list bdepinfo = function
    [] -> None
  | (a::l) ->
      match check_assign2 bdepinfo a with
	None -> 
	  begin
	    match check_assign2_list bdepinfo l with
	      None -> None
	    | Some(charac_type, l') -> Some(charac_type, (any_term_pat a)::l')
	  end
      |	Some(charac_type, a') -> Some(charac_type, a'::(List.map any_term_pat l))


	      let t1' = remove_dep_array_index bdepinfo t1 in
	      match find_compos_list bdepinfo t1' with
		Some(_, charac_type, t1'', b2, b2fromb) ->
		  begin
		    try 
		      let t2' = is_indep bdepinfo t2 in
                      (* add probability; if too large to eliminate collisions, raise Not_found *)
		      if not (add_term_collisions (cur_array, true_facts_from_simp_facts true_facts, [], Terms.make_true()) (subst b2 b2fromb t1'') t2' b (Some (List.map Terms.term_from_repl_index b.args_at_creation)) [charac_type]) then raise Not_found;
		      if (f.f_cat == Diff) then Terms.make_true() else Terms.make_false()
		    with Not_found ->
		      try_dep_info restl
		  end
	      | None -> ...

            let dep_info' = 
              List.map (fun ((b, (dep, nodep)) as bdepinfo) ->
		if depends bdepinfo t then
		  match dep with
		    None -> bdepinfo
		  | Some dl ->
                      match find_compos_list bdepinfo t with
	                Some (st, charac_type, t', b2, b2fromb) -> 
			  (b, (Some ((b',(st, (charac_type, subst b2 b2fromb t')))::dl), nodep))
                      | None -> 
			  let rec find_dep = function
			      [] -> 
				Parsing_helper.internal_error "t does not depend on b; this should have been detected by depends before"
                                (*(b, (dep, (Terms.term_from_binder b')::nodep))*)
			    | (b2, (_, (_, b2fromb)))::dep' ->
				if Terms.refers_to b2 t then
				  (b, (Some ((b', (Any, (b.btype, subst b2 b2fromb t)))::dl), nodep))
				else
				  find_dep dep'
			  in
			  find_dep dl
		else
		  (b, (dep, (Terms.term_from_binder b')::nodep))
                 ) dep_info 
            in

	        let t' = FindCompos.remove_dep_array_index bdepinfo t in
		let pat' = remove_dep_array_index_pat bdepinfo pat in
		match find_compos_list bdepinfo t' with
		  Some (st, charac_type, t'', b2, b2fromb) ->
		    check_assign1 cur_array true_facts (subst b2 b2fromb t'', Terms.term_from_pat pat', b, charac_type) bdepinfo st pat';
		    true
		| None ->
		    begin
		      if depends bdepinfo t' then () else
                      match check_assign2 bdepinfo pat' with
			None -> ()
		      |	Some(charac_type, t1') ->
			  (* Add probability *)
			  if add_term_collisions (cur_array, true_facts_from_simp_facts true_facts, [], Terms.make_true()) t1' t' b (Some (List.map Terms.term_from_repl_index b.args_at_creation)) [charac_type] then
			    raise Else
		    end;
		    (depends bdepinfo t) || (depends_pat bdepinfo pat)



src/transf_simplify.ml:156:  match FindCompos.find_compos check (b, depinfo) (b,(Decompos, (b.btype, Terms.term_from_binder b))) t with

(* Inside DepAnal2.
   Same check as above *)

let find_compos_glob depinfo b t =
  match FindCompos.find_compos check (b, depinfo) (b,(Decompos, (b.btype, Terms.term_from_binder b))) t with
    Some(_, CharacType charac_type, t') -> Some(charac_type, t')
  | Some _ -> Parsing_helper.internal_error "CharacTypeOfVar should not be used in DepAnal2"
  | None -> None

(* Outside DepAnal2 *)

	 let depinfo = DepAnal2.get_dep_info dep_info b in
	 let t1' = FindCompos.remove_dep_array_index (b,depinfo) t1 in
	 match DepAnal2.find_compos_glob depinfo b t1' with
	   None -> None
	 | Some(charac_type, t1'') ->
	    try 
	      let collect_bargs = ref [] in
	      let collect_bargs_sc = ref [] in
	      let (t2', t2_eq) = Facts.is_indep simp_facts (b,l,depinfo,collect_bargs,collect_bargs_sc) t2 in
	      (* We eliminate collisions because t1 characterizes b[l] and t2 does not depend on b[l],
                 In case b occurs in t2, we reason as follows:
                    1/ When the indices of b in t2 are all different from l, t2 does not depend on b[l].
                       We eliminate collisions under that additional condition, hence the equality 
                       t1 = t2 is false in this case.
                       We collect in collect_bargs the indices l_i of b in t2. Hence the additional
                       condition is &&_(l_i in collect_bargs) l <> l_i. This condition is added
                       as side_condition below.
                    2/ Therefore, we can replace t1 = t2 with 
	               (t1 = t2) && (||_(l_i in collect_bargs) l = l_i),
	               which we rewrite
                       ||_(l_i in collect_bargs) (l = l_i && t1 = t2 { l/l_i }) 
		 *)
	      let side_condition = 
		Terms.make_and_list (List.map (fun l' ->
		  Terms.make_or_list (List.map2 Terms.make_diff l l')
		    ) (!collect_bargs_sc))
	      in
	      (* add probability; returns true if small enough to eliminate collisions, false otherwise. *)
	      if add_term_collisions (cur_array, true_facts_from_simp_facts simp_facts, [], side_condition) t1'' t2' b (Some (List.map Terms.term_from_repl_index b.args_at_creation)) [charac_type] then
		Some (Terms.make_or_list (List.map (fun l' ->   
		  let t2'' = Terms.replace l' l t2_eq in
		    Terms.make_and (Terms.make_and_list (List.map2 Terms.make_equal l l')) (Terms.make_equal t1 t2'')
		    ) (!collect_bargs)))
              else
                None
	    with Not_found -> None

src/transf_simplify.ml:586:	match FindCompos.find_compos check (b,(None, [])) (b,(FindCompos.Decompos, ref [FindCompos.CharacType b.btype])) t1 with

	let check (b, (st, _)) l' = 
	  if List.for_all2 Terms.equal_terms l' l then
	    Some (st, FindCompos.CharacTypeOfVar b) 
	  else
	    None
	in
	match FindCompos.find_compos check (b,(None, [])) (b,(FindCompos.Decompos, ref [FindCompos.CharacType b.btype])) t1 with
	  None -> None
	| Some _ -> 
	    if List.memq b (!failure_check_all_deps) then None else
	    begin
	      print_string "Doing global dependency analysis on ";
	      Display.display_binder b;
	      print_string " inside simplify... "; flush stdout;
	      let current_proba_state = Proba.get_current_state() in
	      let current_term_collisions = !term_collisions in
	      match Transf_globaldepanal.check_all_deps b (!proba_state_at_beginning_iteration) (!whole_game) with
		None -> 
		  (* global dependency analysis failed *)
		  print_string "No change"; print_newline();
		  Proba.restore_state current_proba_state;
		  term_collisions := current_term_collisions;
		  failure_check_all_deps := b :: (!failure_check_all_deps);
		  None
	      | Some(res_game) ->
		  (* global dependency analysis succeeded. 
                     Restart simplification from the result of global dep anal *)
		  print_string "Done. Restarting simplify"; print_newline();
		  Settings.changed := true;
		  raise (Restart(b, res_game))
	    end

Three possible results:

- Decompos(l0opt): [t] is obtained from [b0[l0]] by applying decomposition functions,
  which extract part of their argument, when l0opt = Some l0.
  [t] is obtained from [b0[l0']] by applying decomposition functions,
  for some l0', when l0opt = None.
- Compos(p, t_1, l0opt): for all [t'] independent of [b0[l0]], Pr[t = t'] <= p,
  when l0opt = Some l0.
  for all [t'] independent of [b0[l]] for all [l], Pr[t = t'] <= p,
  when l0opt = None.
  [t_1] is a modified version of [t] in which the parts that are not useful
  to show this property are replaced with variables [?].
  [p] is the probability for one test t = t'. It should be multiplied by
  the number of executions outside of find_compos.
  [p] replaces CharacType
- Any: no property proved

Decompos(l0opt) => Compos(PColl1Rand t.t_type, t, l0opt)

The term "assign" in DepAnal2 that defines how to compute a variable from the
initial dependency can be computed outside find_compos, by substituting
all variables that depend on b0 with their values. (Put links for all
these variables to speed up the substitution.)

find_compos (b0, b0depinfo) l0opt t

get_status b[l] =
   if b = b0 then
      if l0opt = Some l || l0opt = None then Decompos(l0opt) else Any
   else
      let (dep, nodep) = b0depinfo in
      match dep with
      | None -> Any
      | Some ldep ->
         try
           let (st, _) = List.assq b ldep in
	   substitute b.args_at_creation with l in l0opt in st
	   if l0opt = Some l' , check that the resulting l0opt' is l'; if not, return Any
	   return st
	 with Not_found -> Any

Add a case "ProbaIndepOfVar b" in the probability formula
associated to the Compos status,
representing a probability p such that
for all M independent of b0[l0], Pr[b[l] = M] <= p
That replaces CharacTypeOfVar.
But how are l0 and l determined?
- l0 comes from l0opt in Compos, any index when l0opt = None
- l coming from the status of b, which must itself be Compos?
  When l0opt = None, l is any index.
  When l0opt = Some l0, the status of b must be Compos(p_b, t_1, Some l0'),
  which tells us b[args_at_creation] depends on b0[l0'].
  Then l is such that l0 = l0'{l/args_at_creation}
  Such an l exists, because it is how l0opt = Some l0 is computed.
  p_b is initially "ProbaIndepOfVar b" and could be replaced with
  the actual value when it has been computed from all definitions of b.
[CANNOT AVOID THAT, even though I can compute the actual probability
from dvar_list *before* the check_depend_process pass:
if b2 is defined from b1 defined from b0,
and I add a definition of b1, I need to update the probability for
b2, and I can do that only if I have the probability for b2 as
a function of the one for b1, using ProbaIndepOfVar b1.]
DONE 23/8/2019 Added ProbaIndepCollOfVar

WARNING: the "dep" component of bdepinfo does not have exactly
the same meaning in DepAnal2 and in globaldepanal:
- In DepAnal2, the information applies only for x[args_at_creation]
- In globaldepanal, it applies for any indices (by substituting
the desired indices for args_at_creation)
find_compos should take this point into account.

Older point:

Write nicer code for dependency analysis, in particular
FindCompos. Perhaps the type of the dependency information
for a variable b0 could be
{ args_at_creation_only: bool; (* True when the dep. info. deals only with variables with indices args_at_creation *)
  dep: (binder * status * depend_args_opt * 'a) list (* List of variables that depend on b0 *)
  other_variables: bool; (* True when variables not in dep may also depend on b0 *)
  nodep: term list } (* List of terms that do not depend on b0 *)

status =
    Compos of charac_type * charac_args_opt
  | Decompos of charac_type * charac_args_opt
  | Any

charac_args_opt = term list option
(* When [Some l], means that b[args_at_creation] charactarizes a part of b0[l] *)

depend_args_opt = term list option
(* When [Some l], means that b[args_at_creation] depends only on b0[l] *)

Still, it may be difficult to write FindCompos without first
having to find out which variable subterm we want to characterize.
(In DepAnal2, there are several possible b0.
 In the dependency_collision_rec3, we can consider all large restrictions...)

====== End of the notes on the change in FindCompos
DONE 5/9/2019

Put FindCompos in a separate file?
Arrange so that the proba state also includes Simplify1.term_collisions?
	term_collisions is used only with dependency analyses
	the functions to add probabilities in this case need simplification of facts,
	which uses more basic functions to add probabilities of collisions (those are in proba.ml)
Or rather write a module for dependency analysis functions, which
includes FindCompos, but also the functions to add the corresponding probabilities.
DONE 12/9/2019

plus/minus: when the mathematical result is >= max_int, make sure that
the obtained result is at least max_int.
Rather take as argument the direction in which we want to approximate:
High: int_res \in [min_int, max_int] and int_res >= min(exact_res, max_int)
Low: int_res \in [min_int, max_int] and int_res <= max(exact_res, min_int)
DONE 13/9/2019

Generalize to collisions M = f(M1...Mn) where f is data, M has status "decompos"
wrt r, and Mi is independent of r for some i (like check_assign1, but f(M1,...Mn)
is a term, not a pattern).
That could even be more generalized:
Pr[M = f(M1...Mn)] <= Pcoll1rand(T) * Prod_{Mi depends on r} |Ti|
where f(T1...Tn):T. The formula above works even if all Mi depend on
r. It also works if several Mi are independent of r.
We just need to make sure that the resulting probability is small
enough using the size estimate. The probability may be small enough
even when all Mi depend on r, in case the image of f consists
of a small subset of T.
In case that estimate is too large, I can continue recursively
in the Mi that depend on r: when they are of the form
f'(...) for some f' that is "data", I can use some subterms of Mi
instead of Mi itself.
EVEN MORE GENERAL:
Generalize is_indep so that it can replace some subterms (not only
indices) that depend on r by ?. is_indep(M) returns
- a term M' that does not depend on r
- the number of values N that the ? variables can take in M'.
To compute is_indep(f(M1...Mn)),
- let T be the type of f(M1...Mn)
- compute is_indep(Mi) = Mi', Ni
- if \Prod Ni <= |T|, then return f(M1', ..., Mn'), \Prod Ni
                      else return ?, |T|
When find_compos(M1) returns Some(p, M1', ...)
and is_indep(M2) returns (M2', n), we have
Pr[M1 = M2] <= p * n and the eliminated collision is M1' = M2'.
Use the size estimates to see whether "\Prod Ni < |T|" above
and whether p * n is small enough.
In the case of check_assign1, that's the same idea, the
bound variables of the pattern (PatVar) being systematically
converted into ? variables.
  [The status of the term does not need to be Decompos]
PROBLEM: that requires really good size estimates.
Distinguish the estimate for the cardinal |T|
from the one for the probability Pcoll1rand(T)/Pcoll2rand(T)
for nonuniform types.
    tsize: int option
    tpcoll: int option (* Use None when it is not set *)
If I do not trust the size estimates, I could use the following:
In is_indep:
- when f is [data], I know that \Prod Ni <= |T|.
- when \Prod Ni = 1 (ie M1...Mn are really independent of r)
  I know that \Prod Ni <= |T|.
- otherwise, assume that \Prod Ni > |T|
Require explicit declarations in allowed_collisions for
p * n.
Or better: for f(f'(...),...) return a number of value
estimate |T|/\Prod_{subterms M indep of r} |Type(M)|.
This estimate is always greater than the real number of values.
If |T| simplifies in the product with p, we obtain
1 / \Prod_{subterms M indep of r} |Type(M)|
If one of these types is large (= larger than the size estimate
in allowed_collisions) we eliminate the collision.
DONE 13/9/2019

   Use allowed_collisions to set "tysize_MIN_Manual_Coll_Elim" and
set trust_size_estimates := true.
Remove the setting trustSizeEstimates
When !trust_size_estimates, compute the estimate for the whole
probability (including replication bounds) and compare that to
tysize_MIN_Manual_Coll_Elim.
Document the recent changes of probability estimates
===> There are two sets of parameters:
1/when trust_size_estimates=false:
  allowed_collisions
  allowed_collisions_collision
  tysize_MIN_Manual_Coll_Elim => can be computed from allowed_collisions:
       minimum type bound in allowed_collisions
The default treatment of bounds is closer to asymptotic security:
large types considered exponential, while parameters are always
polynomial, so any product of parameters is acceptable.
2/when trust_size_estimates=true:
  tysize_MIN_Manual_Coll_Elim:  allowed_collisions max_proba pest<n>
This is better for exact security.

Use log2(v) as estimate for Cst v?
Increase the estimate by one if we add two equal estimates?
Case Sub in Proba.order_of_magnitude?
Case of negative values? (especially negative constants) Carry a sign?
===> In Proba.order_of_magnitude,
     Use interval arithmetic, with bounds (signed)mantisse*2^exponent.
     Use a float to represent that?
     Or a float for mantisse and an integer for exponent?
     Or an integer for mantisse and one for exponent?
     Or sign*2^f, where sign is -1, 0, or 1, and f is a float?
     (The latter may be simpler, since we need to look at the sign anyway
     for division.)
DONE 17/9/2019
   
In facts.ml: Terms.get_pcoll1 b1.btype High <= -1
or <= !Settings.tysize_MIN_Manual_Coll_Elim ? I used the latter for now.

Allow giving an interval for size and probability estimates, e.g.
size<min>_<max> pcoll<min>_<max> pest<min>_<max>?
That would be fairly easy given how I use the estimates, but may
not be essential.
DONE for size<min>_<max>; for probabilities and size of parameters,
we only give an upper bound.

   src/proba.ml:  | Maxlength(n,t) -> Maxlength(!whole_game, Terms.copy_term Terms.Links_Vars t) (* When add_proba_red is called, the variables in the reduction rule are linked to their corresponding term *)
=> This comment is wrong now!!! there is a bug here...
see examplesnd/test/pcoll_instantiation.cv
strange that it instantiates x1 but not y1. It should instantiate both,
but given the bug, I would expect it to instantiate none.
FIXED 23/9/2019

Simplify1.matches might forget some collisions that should in fact remain,
when the variables have the same name in different collisions, but
actually a different content -- perhaps taking the maximum of the probabilities,
or requiring that the probabilities match, would solve the issue,
as in this situation the two collisions are applied with different
values of the indices for the common variables.
I do not manage to exhibit the bug:
- in global_dep_anal, in case a variable has several definitions
in the whole game, this is taken care of in its status using
ProbaIndepCollOfVar and in Transf_globaldepanal.compute_probas.
- in DepAnal2, the variables are replaced with their value.
FIXED 24/9/2019 For safety, merge collisions only when probabilities are equal

Apply collisions as well in the binary case of Simplify1.FindCompos.find_compos_gen
(possibly by modifying function Simplify1.FindCompos.apply_eq_statements
For counting of probabilities in FindCompos, for a collision
M = M' where M characterizes b and M' is independent of b
In case find_compos_bin, the fresh variables that I create should
use as indices the list of indices of M'. However, that list of
indices is not known at this point, so perhaps create a fresh replication
index, use it for the indices of fresh variables for find_compos_bin,
and replace later by the real list of indices when I have it?
Or pass the indices of M' as argument? But for that, I need to know
to indices introduced by is_indep. I can know them by calling is_indep
before find_compos.
However, when I evaluate find_compos for expressions M in 
let x = M, I do not know which independent term will be compared with x.
So in this case, I cannot have the indices.
So it is probably better to create a fresh replication
index, use it for the indices of fresh variables for find_compos_bin,
and replace later by the real list of indices when I have it...
   - create fresh repl index (size0), use it as index for variables in
   find_compos_bin
   - start from an empty probability state.
   - get the probability state at the end of find_compos, and
      return as status: the fresh repl index, that probability state,
      in addition to the probability already returned.
      The proba state consists of
      * list of (b1,b2) corresponding to a proba
      pcoll2rand b1.btype * indices at creation of b1 and b2 * (0.5 if b1 == b2)
      * list of (t1,t2,side_cond,indices,probaf_mul_types) corresponding to a proba
      probaf_mul_types * product of |indices|

      In the first list, the indices at creation should not contain the fresh
      index created by find_compos. They are unaffected when we recreate
      the probability for collision.
      In the second list, we need to replace the fresh index in indices with
      the indices of the term t_indep and update probaf_mul_types
      with (dep_types, indep_types_opt) from is_indep:

      prod (dep_types, full_type, indep_types_opt) (dep_types', full_type', indep_types_opt') =
        if dep_types == [] then
	   (dep_types', full_type', indep_types_opt')
	else if dep_types' == [] then
	   (dep_types, full_type, indep_types_opt)
	else
	   match indep_types_opt, indep_types_opt' with
	   | None, _ | _, None ->
	       (dep_types @ dep_types', full_type, None) (* full_type does not matter *)
	   | Some indep_types, Some indep_types' ->
	       (* prod dep_types * prod dep_types' <= full_type * full_type' / (prod indep_types * prod indep_types') *)
	       if List.memq full_type indep_types' then
	          (dep_types @ dep_types', full_type', Some (indep_types @ indep_types' \ full_type))
	       else if List.memq full_type' indep_types then
	          (dep_types @ dep_types', full_type, Some (indep_types @ indep_types' \ full_type'))
	       else
	          (dep_types @ dep_types', full_type, None) (* full_type does not matter *)

      Use the following dependency analysis ([bdepinfo] is the argument given to [find_compos])
      to call [apply_reds depth (dependency_anal bdepinfo) simp_facts t]

let dependency_anal bdepinfo = 
  let indep_test = Facts.default_indep_test bdepinfo in
  let collision_test simp_facts t1 t2 = None in
  (indep_test, collision_test)
DONE 3/10/2019

Allow entering assumptions as "equiv ..." without a replication
   at the top of each side. In this case, add the replication automatically
   by the following result:
   P <=(p)=> Q  implies  !N P <=(N p{time + (N-1)max(t_P,t_Q)/time})=> !N Q
   proved by a hybrid argument.
For [computational] equivalences,
   P <=(p)=> Q  implies  !N P <=(N p{time + (N-1)t_P/time})=> !N Q
DONE 14/10/2019

preserve occurrences in module DepAnal2, because they are
then used in simplify.
DONE 18/10/2019

Allow non-expanded games (some transformations will not be supported
on non-expanded games; they will display a message and leave the game
unchanged).
Separate the transformations crypto / simplify (non-expanded) / expand.
DONE 21/10/2019

Simplify1.improved_def_process does not support non-expanded games,
just fall back to the standard def_process
DONE 21/10/2019

Allow insert_event in terms.
DONE 22/10/2019
Allow replace on non-expanded games.
DONE 23/10/2019
Test commands on non-expanded games!
DONE 24/10/2019

Note: When "collision" statements are used in the simplification that
follows a cryptographic transformation, the simplified game is not
displayed, and as a result, the corresponding times are printed as:
time(context for game -1) which is not good, especially when there
are several such games involved...
==> Will be solved by considering crypto, simplify, expand as
separate transformations (and thus allowing non-expanded
intermediate games)
DONE 21/10/2019

Use new_occ only in terms.move_occ; otherwise, use -1,
and display [occ not set] if it is used.
DONE 21/10/2019

rename mergeBranches into autoMergeBranches
mergeArrays into autoMergeArrays
DONE 23/10/2019

Specify hidden_key_collision_resistance,
DONE 28/10/2019
second_preimage_resistance, hidden_key_second_preimage_resistance,
   fixed_hash_second_preimage_resistance
DONE 28/10/2019

preimage_resistance, hidden_key_preimage_resistance,
   fixed_hash_preimage_resistance
DONE 31/10/2019
see https://eprint.iacr.org/2004/035 (consider random challenge only)

      - Be able to consider a call to the hash function as a call to
      the hash oracle given to the adversary. That could be useful
      when we do not really care about this call, e.g., when it is in
      a session with a dishonest peer for which we do not prove
      security. Hard with the current language. Perhaps with an oracle
      call construct?
      Problem: that would be as if we give the arguments of the oracle to
      the adversary.
      More generally, be able to consider several calls to a hash
      oracle as a single case, like a call to a common subroutine,
      when distinguishing the cases is useless.

      A nice way to do that:

equiv(rom(hash))
      foreach ih <= Nh do k <-R key;
        (foreach i <= N do OH(x1: hashinput1) := return(hash(k, x1)) |
         foreach i <= Ndont_care do OHdont_care(x1dont_care: hashinput1) := return(hash(k, x1dont_care)) |
         foreach ieq <= Neq do Oeq(x1': hashinput1, r': hashoutput) := return(r' = hash(k, x1')) |
         foreach icoll <= Ncoll do Ocoll(y1: hashinput1, z1: hashinput1) := 
                 return(hash(k, y1) = hash(k, z1)))
       <=(#Oeq * Pcoll1rand(hashoutput) + #Ocoll * Pcoll2rand(hashoutput))=> [manual]
      foreach ih <= Nh do 
        (foreach i <= N do OH(x1: hashinput1) := 
	   find[unique] u <= N suchthat defined(x1[u], r[u]) && x1 = x1[u] then return(r[u])
	   orfind u <= N suchthat defined(x1dont_care[u]) && x1 = x1dont_care[u] then return(hash(k, x1)) else
           r <-R hashoutput; return(r) |
	 foreach i <= Ndont_care do OHdont_care(x1dont_care: hashinput1) :=
	   find[unique] u <= N suchthat defined(x1[u], r[u]) && x1dont_care = x1[u] then return(r[u]) else
	   return(hash(k, x1dont_care)) |
         foreach ieq <= Neq do Oeq(x1': hashinput1, r': hashoutput) := 
           find[unique] u <= N suchthat defined(x1[u], r[u]) && x1' = x1[u] then return(r' = r[u])
	   orfind u <= N suchthat defined(x1dont_care[u]) && x1 = x1dont_care[u] then return(r' = hash(k, x1)) else
	   return(false) |
         foreach icoll <= Ncoll do Ocoll(y1: hashinput1, z1: hashinput1) := 
                 return(y1 = z1)).
      
This version distinguishes between useful calls (OH, Oeq) and useless ones (OHdont_care).
Only the useful calls are transformed.


Version 2:

equiv(rom(hash))
      foreach ih <= Nh do k <-R key;
        (foreach i <= N do OH(x1: hashinput1) := return(hash(k, x1)) |
         foreach i <= Ndont_care do OHdont_care(x1dont_care: hashinput1) := return(hash(k, x1dont_care)) |
         foreach ieq <= Neq do Oeq(x1': hashinput1, r': hashoutput) := return(r' = hash(k, x1')) |
         foreach icoll <= Ncoll do Ocoll(y1: hashinput1, z1: hashinput1) := 
                 return(hash(k, y1) = hash(k, z1)))
       <=(#Oeq * Pcoll1rand(hashoutput) + #Ocoll * Pcoll2rand(hashoutput))=> [manual]
      foreach ih <= Nh do 
        (foreach i <= N do OH(x1: hashinput1) := 
	   find[unique] u <= N suchthat defined(x1[u], r[u]) && x1 = x1[u] then return(r[u])
	   orfind u <= N suchthat defined(x1dont_care[u]) && x1 = x1dont_care[u] then return(event_abort collision) else
           r <-R hashoutput; return(r) |
	 foreach i <= Ndont_care do OHdont_care(x1dont_care: hashinput1) :=
	   find[unique] u <= N suchthat defined(x1[u], r[u]) && x1dont_care = x1[u] then return(event_abort collision) else
	   return(hash(k, x1dont_care)) |
         foreach ieq <= Neq do Oeq(x1': hashinput1, r': hashoutput) := 
           find[unique] u <= N suchthat defined(x1[u], r[u]) && x1' = x1[u] then return(r' = r[u])
	   orfind u <= N suchthat defined(x1dont_care[u]) && x1 = x1dont_care[u] then return(event_abort collision) else
	   return(false) |
         foreach icoll <= Ncoll do Ocoll(y1: hashinput1, z1: hashinput1) := 
                 return(y1 = z1)).
      
This version executes event_abort collision in case of collision between a useful call (OH, Oeq) and a useless one (OHdont_care).
I think it is better. Anyway, we will have to show the absence of such collisions. Using event_abort allows to remove
immediately the code that happens after these collisions and thus simplifies the game considerably.
Obviously, the user has to specify manually whether each call to hash is useful (OH, Oeq) or useless (OHdont_care),
by specifying which oracle to use for each term.

Note: if we keep the same function hash in the RHS of the equivalence, 
we can apply the same equivalence again on the remaining calls to hash
if needed.

I could push this idea further by having several oracles that call H, called OH1,...,OHk.
When an argument to OHi is equal to an argument of OHj for i<>j, event_abort collision.
Otherwise, compare the argument of OHi with the previous arguments of OHi.
That allows to show a posteriori that there no collisions between arguments
of OHi and OHj for i<>j without experiencing a big blow-up.
Perhaps sometimes one oracle can collide with all others (or with several others),
e.g. the oracle of the adversary... How to adapt the equivalence to the various
cases? Perhaps enough to allow:
- the OH oracle, which returns ri in case of collision with OHi,
  and returns hash(x) otherwise 
- the OH_cut oracle, which executes event_abort collision in case of
  collision with OHi, and returns hash(x) otherwise.
- OH_i, which executes event_abort collision in case of collision with OHj
  with i<>j or OH_cut, returns hash(x) in case of collision with
  OH, returns the previous ri in case of collision with a
  previous call to OHi, and returns a fresh ri otherwise. 
   let's say 1<=i,j<=10.

- Oeq, which returns ri = r in case of collision with OHi,
  and returns hash(x) = r otherwise
- Oeq_cut, which executes event_abort collision in case of
  collision with OHi, returns hash(x) = r otherwise
- Oeq_i, which executes event_abort collision in case of collision with OHj
  with i<>j or OH_cut, returns hash(x) = r in case of collision with
  OH, returns the previous ri = r in case of collision
  with OHi, and returns false otherwise

[[Other option:
- Oeq, which returns ri = r in case of collision with OHi,
  returns hash(x) = r  in case of collision with OH_cut or
  OH, and returns false otherwise
- Oeq_cut, which executes event_abort collision in case of
  collision with OHi, returns hash(x) = r in case of collision with
  OH_cut or OH, and returns false otherwise
]]

The same idea applies to PRFs
DONE 28/10/2019

Distinguish ROM / ROM_large like I do for PRFs?
DONE 28/10/2019

Fix internal error in
examplesnd/otest/internal_error_cryptotransf_useknownequalities.ocv
FIXED 5/11/2019
